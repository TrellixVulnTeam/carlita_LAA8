{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import threading\n",
    "\n",
    "from train_utils import *\n",
    "\n",
    "import gym3\n",
    "from procgen import ProcgenGym3Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_levels = 100_000 #500 #1500\n",
    "train_start_level = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building procgen...done\n"
     ]
    }
   ],
   "source": [
    "bs = 256 #144 \n",
    "\n",
    "env = ProcgenGym3Env(num=bs, env_name=\"testgame\", num_levels=train_num_levels, start_level=train_start_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.55 s, sys: 230 ms, total: 4.78 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s = np.array([[.0,.0] for _ in range(bs)], dtype=np.float32)\n",
    "\n",
    "seq_len = 200\n",
    "\n",
    "for i in range(seq_len):\n",
    "    env.act(s)\n",
    "    rew, obs, first = env.observe()\n",
    "    img = obs['rgb']\n",
    "    info = env.get_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([400, 256, 3, 64, 64]) took 3.08 seconds\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(env=env, bs=bs, seq_len=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "front, aux, target = dataloader.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([400, 256, 3, 64, 64]),\n",
       " torch.Size([400, 256, 5]),\n",
       " torch.Size([400, 256, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front.shape, aux.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = VizCNN(use_rnn=True).to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VizCNN(\n",
       "  (pooler): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (act): ReLU()\n",
       "  (conv_1a): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (conv_2a): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv_2b): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv_3a): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv_4a): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc0): Linear(in_features=5413, out_features=512, bias=True)\n",
       "  (lstm): LSTM(512, 512)\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.load_state_dict(torch.load(\"m.torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5229.507"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([torch.numel(p) for p in m.parameters()]) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hidden = get_hidden(bs)\n",
    "    out, hidden = m(front[:6].to(device), aux[:6].to(device), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del front, aux, target, out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdrive(in_distribution=True, calibrate=False, use_training_wheels=False):\n",
    "    \n",
    "    TRAINING_WHEELS_WINDOW = 30\n",
    "    \n",
    "    t1 = time.time()\n",
    "    m.eval()\n",
    "    seq_len = 1000\n",
    "    n_val = 100\n",
    "    val_env = ProcgenGym3Env(num=n_val, \n",
    "                            env_name=\"testgame\", \n",
    "                            num_levels=train_num_levels, \n",
    "                            start_level=train_start_level if in_distribution else train_start_level+train_num_levels)\n",
    "    \n",
    "    s = np.array([[.0,.0] for _ in range(n_val)], dtype=np.float32)\n",
    "    reward = 0\n",
    "    num_collisions = 0\n",
    "    wp_infractions = 0\n",
    "    successful_stops = 0\n",
    "    \n",
    "    hidden = get_hidden(n_val)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(seq_len):\n",
    "            val_env.act(s)\n",
    "            rew, obs, first = val_env.observe()\n",
    "            reward += rew.sum()\n",
    "            img = obs['rgb']\n",
    "            info = val_env.get_info()\n",
    "            num_collisions += np.array([e['collision'] for e in info]).sum()\n",
    "            wp_infractions += np.array([e['waypoint_infraction'] for e in info]).sum()\n",
    "            successful_stops += np.array([e['successful_stop'] for e in info]).sum()\n",
    "            \n",
    "            autopilot_control = np.array([[e[\"autopilot_\"+c] for c in control_properties] for e in info])\n",
    "            \n",
    "            aux = np.array([[e[a] for a in aux_properties] for e in info])\n",
    "\n",
    "            front = torch.from_numpy(img.astype(np.float32)/255.).unsqueeze(0).permute(0,1,4,2,3).to(device)\n",
    "            \n",
    "            aux = torch.from_numpy(aux.astype(np.float32)).unsqueeze(0).to(device)\n",
    "            \n",
    "            if calibrate:\n",
    "                s = autopilot_control\n",
    "            else:\n",
    "                out, hidden = m(front, aux, hidden)\n",
    "                s = out.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "                s = np.clip(s, -5., 5.)\n",
    "                \n",
    "            if use_training_wheels and i < TRAINING_WHEELS_WINDOW:\n",
    "                s = autopilot_control\n",
    "        \n",
    "\n",
    "    reward /= (n_val*seq_len)\n",
    "    num_collisions /= (n_val*seq_len)\n",
    "    wp_infractions /= (n_val*seq_len)\n",
    "    successful_stops /= (n_val*seq_len)\n",
    "    \n",
    "    val_env.close()\n",
    "    m.train()\n",
    "    print(f\"validation took {round(time.time()-t1)} seconds\")\n",
    "    return reward, num_collisions, wp_infractions, successful_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation took 8 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01994, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdrive(in_distribution=True, calibrate=False, use_training_wheels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss().cuda()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "opt = torch.optim.Adam(m.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wandb.init(project=\"carlita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.watch(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_epoch(train=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Caching baseline 'perfect' scores for val use. A bit awkward placement\n",
    "    autopilot_score_baseline_in_dist, autopilot_collisions_in_dist, _, ap_successful_stops_in = testdrive(in_distribution=True, calibrate=True)\n",
    "    #autopilot_score_baseline_out_dist, autopilot_collisions_out_dist, _, ap_successful_stops_out = testdrive(in_distribution=False, calibrate=True)\n",
    "    \n",
    "    m.train(train)\n",
    "    t1 = time.time()\n",
    "    epoch_loss, preds = [], []\n",
    "    #bs = random.choice(list(bs_bptt_lookup.keys()))\n",
    "    bptt = 32 #random.choice([64, 72, 80, 88]) # increasing for 32x32 data #bs_bptt_lookup[bs]\n",
    "    \n",
    "    val_cadence = 8\n",
    "    log_cadence = 4\n",
    "    \n",
    "    global dataloader, bs\n",
    "    #dataloader = DataLoader(bs=bs) \n",
    "    log_counter = 0\n",
    "    \n",
    "    #hidden_reset_counter = 0\n",
    "    #hidden_reset_cadence = 8\n",
    "    \n",
    "    while True:\n",
    "        chunk = dataloader.get_chunk() # Returns a chunk instantly, begins queuing up another chunk async\n",
    "        if not chunk: break\n",
    "        front_container, aux_container, target_container = chunk\n",
    "        chunk_len, bs, _, _, _ = front_container.shape\n",
    "        len_ix = 0\n",
    "        chunk_loss = []\n",
    "        \n",
    "        hidden = get_hidden(bs) # Resetting each chunk, ie each 800 steps or so\n",
    "        \n",
    "        while len_ix < chunk_len:\n",
    "            \n",
    "            #if hidden_reset_counter % hidden_reset_cadence == 0:\n",
    "            #    hidden = get_hidden(bs)\n",
    "            #    print(\"Resetting hidden\")\n",
    "            #hidden_reset_counter+=1\n",
    "                \n",
    "            front = front_container[len_ix:len_ix+bptt, :, :, :, :].to(device).half()\n",
    "            aux = aux_container[len_ix:len_ix+bptt, :, :].to(device).half();\n",
    "            target = target_container[len_ix:len_ix+bptt, :, :].to(device).half()\n",
    "            len_ix += bptt\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred, hidden = m(front, aux, hidden)\n",
    "                \n",
    "            loss = loss_fn(target, pred); \n",
    "            chunk_loss.append(loss.item())\n",
    "                \n",
    "            if train:\n",
    "                # Scales the loss, and calls backward() to create scaled gradients \n",
    "                scaler.scale(loss).backward() \n",
    "                \n",
    "                # Unscales the gradients of optimizer's assigned params in-place\n",
    "                scaler.unscale_(opt)\n",
    "                # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                torch.nn.utils.clip_grad_norm_(m.parameters(), 5.)\n",
    "\n",
    "        \n",
    "                # Unscales gradients and calls or skips optimizer.step() \n",
    "                scaler.step(opt) \n",
    "                # Updates the scale for next iteration \n",
    "                scaler.update() \n",
    "                opt.zero_grad()\n",
    "                \n",
    "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "\n",
    "        # Save and report at end of each chunk\n",
    "        t2 = time.time()\n",
    "        chunk_loss = np.round(np.array(chunk_loss).mean(), 4)\n",
    "        epoch_loss.append(chunk_loss)\n",
    "        total_seconds = round(t2 - t1)\n",
    "        \n",
    "        if train and log_counter % log_cadence == 0 and log_counter>1: \n",
    "            \n",
    "            current_time = time.time()\n",
    "            torch.save(m.state_dict(), 'm.torch')\n",
    "            \"\"\"wandb.log({\"Chunk Loss\": chunk_loss, \n",
    "                       \"Seconds per iter\":total_seconds, \n",
    "                       'LR':opt.param_groups[0]['lr'],\n",
    "                       \"Total time (min)\":round((time.time()-start_time) / 60)\n",
    "                      })\"\"\"\n",
    "            print(f'Done with chunk. Training took {total_seconds} seconds. Chunk loss was {chunk_loss}\\n')\n",
    "            \n",
    "        if log_counter % val_cadence == 0:\n",
    "            val_score_in_dist, collisions_in_dist, wp_infractions_in_dist, stops_in = testdrive(in_distribution=True, use_training_wheels=True) \n",
    "            val_score_in_dist /= autopilot_score_baseline_in_dist\n",
    "            #collisions_in_dist /= autopilot_collisions_in_dist\n",
    "            #stops_in /= ap_successful_stops_in\n",
    "            \n",
    "            #val_score_out_dist, collisions_out_dist, wp_infractions_out_dist, stops_out = testdrive(in_distribution=False, use_training_wheels=True)\n",
    "            #val_score_out_dist /= autopilot_score_baseline_out_dist\n",
    "            #collisions_out_dist /= autopilot_collisions_out_dist\n",
    "            #stops_out /= ap_successful_stops_out\n",
    "            \n",
    "            print(f\"val score in dist: {np.round(val_score_in_dist,2)}\")\n",
    "            print(f\"collisions in dist: {np.round(collisions_in_dist,2)}\")\n",
    "            #print(f\"wp infractions in dist: {wp_infractions_in_dist}, out dist: {wp_infractions_out_dist}\")\n",
    "            \n",
    "            \"\"\"wandb.log({\"val score indist\":val_score_in_dist, \n",
    "                       #\"val score outdist\":val_score_out_dist,\n",
    "                       \"collisions indist\":collisions_in_dist, \n",
    "                       #\"collisions outdist\":collisions_out_dist,\n",
    "                        #\"wp infractions indist\":wp_infractions_in_dist, \n",
    "                       #\"wp infractions outdist\":wp_infractions_out_dist,\n",
    "                        \"stops indist\":stops_in, \n",
    "                       #\"stops outdist\":stops_out\n",
    "                      })\"\"\"\n",
    "            \n",
    "        t1 = t2\n",
    "        log_counter+=1\n",
    "    \n",
    "    loss = np.array(epoch_loss).mean()\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation took 4 seconds\n",
      "Queueing chunk of size torch.Size([400, 256, 3, 64, 64]) took 3.18 seconds\n",
      "validation took 8 seconds\n",
      "val score in dist: 0.08\n",
      "collisions in dist: 0.02\n",
      "Queueing chunk of size torch.Size([400, 256, 3, 64, 64]) took 3.59 seconds\n",
      "Queueing chunk of size torch.Size([400, 256, 3, 64, 64]) took 3.41 seconds\n"
     ]
    }
   ],
   "source": [
    "run_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
