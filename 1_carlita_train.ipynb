{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import threading\n",
    "\n",
    "from train_utils import *\n",
    "\n",
    "import gym3\n",
    "from procgen import ProcgenGym3Env\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_levels = 100_000 #500 #1500\n",
    "train_start_level = 0\n",
    "color_themes_indist = 1\n",
    "color_themes_outdist = 234567\n",
    "\n",
    "color_themes_road_indist = 2\n",
    "color_themes_road_outdist = 134567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building procgen...done\n"
     ]
    }
   ],
   "source": [
    "bs = 144 \n",
    "\n",
    "env = ProcgenGym3Env(num=bs, env_name=\"testgame\", num_levels=train_num_levels, start_level=train_start_level,\n",
    "                    color_theme=color_themes_indist, color_theme_road=color_themes_road_indist,\n",
    "                    background_noise_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 146 ms, total: 2.89 s\n",
      "Wall time: 797 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s = np.array([[.0,.0] for _ in range(bs)], dtype=np.float32)\n",
    "\n",
    "seq_len = 200\n",
    "\n",
    "for i in range(seq_len):\n",
    "    env.act(s)\n",
    "    rew, obs, first = env.observe()\n",
    "    img = obs['rgb']\n",
    "    info = env.get_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fefcc1056a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.11 seconds\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(env=env, bs=bs, seq_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "front, aux, target = dataloader.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 144, 3, 64, 64]),\n",
       " torch.Size([200, 144, 5]),\n",
       " torch.Size([200, 144, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front.shape, aux.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.15 seconds\n"
     ]
    }
   ],
   "source": [
    "m = VizCNN(use_rnn=False).to(device);\n",
    "\n",
    "#m = EfficientNet.from_pretrained('efficientnet-b4', in_channels=3, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VizCNN(\n",
       "  (pooler): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (act): ReLU()\n",
       "  (conv_1a): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2a): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2b): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_3a): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_4a): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (fc0): Linear(in_features=5189, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.load_state_dict(torch.load(\"m.torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3192.834"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([torch.numel(p) for p in m.parameters()]) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hidden = get_hidden(bs)\n",
    "    out, hidden = m(front[:6].to(device), aux[:6].to(device), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del front, aux, target, out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdrive(in_distribution=True, calibrate=False, use_training_wheels=False):\n",
    "    \n",
    "    TRAINING_WHEELS_WINDOW = 10\n",
    "    \n",
    "    t1 = time.time()\n",
    "    m.eval()\n",
    "    seq_len = 300\n",
    "    n_val = 100\n",
    "    val_env = ProcgenGym3Env(num=n_val, \n",
    "                            env_name=\"testgame\", \n",
    "                            num_levels=train_num_levels, \n",
    "                            start_level=train_start_level if in_distribution else train_start_level+train_num_levels,\n",
    "                            color_theme=color_themes_indist if in_distribution else color_themes_outdist,\n",
    "                            color_theme_road=color_themes_road_indist if in_distribution else color_themes_road_outdist,\n",
    "                            background_noise_level = 0 if in_distribution else 100\n",
    "                            )\n",
    "    \n",
    "    s = np.array([[.0,.0] for _ in range(n_val)], dtype=np.float32)\n",
    "    reward = 0\n",
    "    num_collisions = 0\n",
    "    wp_infractions = 0\n",
    "    successful_stops = 0\n",
    "    \n",
    "    hidden = get_hidden(n_val)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(seq_len):\n",
    "            val_env.act(s)\n",
    "            rew, obs, first = val_env.observe()\n",
    "            reward += rew.sum()\n",
    "            img = obs['rgb']\n",
    "            info = val_env.get_info()\n",
    "            num_collisions += np.array([e['collision'] for e in info]).sum()\n",
    "            wp_infractions += np.array([e['waypoint_infraction'] for e in info]).sum()\n",
    "            successful_stops += np.array([e['successful_stop'] for e in info]).sum()\n",
    "            \n",
    "            autopilot_control = np.array([[e[\"autopilot_\"+c] for c in control_properties] for e in info])\n",
    "            \n",
    "            aux = np.array([[e[a] for a in aux_properties] for e in info])\n",
    "\n",
    "            front = torch.from_numpy(img.astype(np.float32)/255.).unsqueeze(0).permute(0,1,4,2,3).to(device)\n",
    "            \n",
    "            aux = torch.from_numpy(aux.astype(np.float32)).unsqueeze(0).to(device)\n",
    "            \n",
    "            if calibrate:\n",
    "                s = autopilot_control\n",
    "            else:\n",
    "                out, hidden = m(front, aux, hidden)\n",
    "                s = out.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "                s = np.clip(s, -5., 5.)\n",
    "                \n",
    "            if use_training_wheels and i < TRAINING_WHEELS_WINDOW:\n",
    "                s = autopilot_control\n",
    "        \n",
    "\n",
    "    reward /= (n_val*seq_len)\n",
    "    num_collisions /= (n_val*seq_len)\n",
    "    wp_infractions /= (n_val*seq_len)\n",
    "    successful_stops /= (n_val*seq_len)\n",
    "    \n",
    "    val_env.close()\n",
    "    m.train()\n",
    "    print(f\"validation took {round(time.time()-t1)} seconds\")\n",
    "    return reward, num_collisions, wp_infractions, successful_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation took 16 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0491, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdrive(in_distribution=False, calibrate=False, use_training_wheels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss().cuda()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "opt = torch.optim.Adam(m.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wandb.init(project=\"carlita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.watch(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_epoch(train=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Caching baseline 'perfect' scores for val use. A bit awkward placement\n",
    "    autopilot_score_baseline_in_dist, autopilot_collisions_in_dist, _, ap_successful_stops_in = testdrive(in_distribution=True, calibrate=True)\n",
    "    autopilot_score_baseline_out_dist, autopilot_collisions_out_dist, _, ap_successful_stops_out = testdrive(in_distribution=False, calibrate=True)\n",
    "    \n",
    "    m.train(train)\n",
    "    t1 = time.time()\n",
    "    epoch_loss, preds = [], []\n",
    "    #bs = random.choice(list(bs_bptt_lookup.keys()))\n",
    "    bptt = 1 #32 #random.choice([64, 72, 80, 88]) # increasing for 32x32 data #bs_bptt_lookup[bs]\n",
    "    \n",
    "    val_cadence = 8\n",
    "    log_cadence = 4\n",
    "    \n",
    "    global dataloader, bs\n",
    "    #dataloader = DataLoader(bs=bs) \n",
    "    log_counter = 0\n",
    "    \n",
    "    #hidden_reset_counter = 0\n",
    "    #hidden_reset_cadence = 8\n",
    "    \n",
    "    while True:\n",
    "        chunk = dataloader.get_chunk() # Returns a chunk instantly, begins queuing up another chunk async\n",
    "        if not chunk: break\n",
    "        front_container, aux_container, target_container = chunk\n",
    "        chunk_len, bs, _, _, _ = front_container.shape\n",
    "        len_ix = 0\n",
    "        chunk_loss = []\n",
    "        \n",
    "        hidden = get_hidden(bs) # Resetting each chunk, ie each 800 steps or so\n",
    "        \n",
    "        while len_ix < chunk_len:\n",
    "            \n",
    "            #if hidden_reset_counter % hidden_reset_cadence == 0:\n",
    "            #    hidden = get_hidden(bs)\n",
    "            #    print(\"Resetting hidden\")\n",
    "            #hidden_reset_counter+=1\n",
    "                \n",
    "            front = front_container[len_ix:len_ix+bptt, :, :, :, :].to(device).half()\n",
    "            aux = aux_container[len_ix:len_ix+bptt, :, :].to(device).half();\n",
    "            target = target_container[len_ix:len_ix+bptt, :, :].to(device).half()\n",
    "            len_ix += bptt*4\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred, hidden = m(front, aux, hidden)\n",
    "                \n",
    "            loss = loss_fn(target, pred); \n",
    "            chunk_loss.append(loss.item())\n",
    "                \n",
    "            if train:\n",
    "                # Scales the loss, and calls backward() to create scaled gradients \n",
    "                scaler.scale(loss).backward() \n",
    "                \n",
    "                # Unscales the gradients of optimizer's assigned params in-place\n",
    "                scaler.unscale_(opt)\n",
    "                # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                torch.nn.utils.clip_grad_norm_(m.parameters(), 5.)\n",
    "        \n",
    "                # Unscales gradients and calls or skips optimizer.step() \n",
    "                scaler.step(opt) \n",
    "                # Updates the scale for next iteration \n",
    "                scaler.update() \n",
    "                opt.zero_grad()\n",
    "                \n",
    "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "\n",
    "        # Save and report at end of each chunk\n",
    "        t2 = time.time()\n",
    "        chunk_loss = np.round(np.array(chunk_loss).mean(), 4)\n",
    "        epoch_loss.append(chunk_loss)\n",
    "        total_seconds = round(t2 - t1)\n",
    "        \n",
    "        if train and log_counter % log_cadence == 0 and log_counter>1: \n",
    "            \n",
    "            current_time = time.time()\n",
    "            torch.save(m.state_dict(), 'm.torch')\n",
    "            \"\"\"wandb.log({\"Chunk Loss\": chunk_loss, \n",
    "                       \"Seconds per iter\":total_seconds, \n",
    "                       'LR':opt.param_groups[0]['lr'],\n",
    "                       \"Total time (min)\":round((time.time()-start_time) / 60)\n",
    "                      })\"\"\"\n",
    "            print(f'Done with chunk. Training took {total_seconds} seconds. Chunk loss was {chunk_loss}\\n')\n",
    "            \n",
    "        if log_counter % val_cadence == 0:\n",
    "            val_score_in_dist, collisions_in_dist, wp_infractions_in_dist, stops_in = testdrive(in_distribution=True, use_training_wheels=False) \n",
    "            val_score_in_dist /= autopilot_score_baseline_in_dist\n",
    "            #collisions_in_dist /= autopilot_collisions_in_dist\n",
    "            #stops_in /= ap_successful_stops_in\n",
    "            \n",
    "            val_score_out_dist, collisions_out_dist, wp_infractions_out_dist, stops_out = testdrive(in_distribution=False, use_training_wheels=True)\n",
    "            val_score_out_dist /= autopilot_score_baseline_out_dist\n",
    "            #collisions_out_dist /= autopilot_collisions_out_dist\n",
    "            #stops_out /= ap_successful_stops_out\n",
    "            \n",
    "            print(f\"val score in dist: {np.round(val_score_in_dist,2)}\")\n",
    "            print(f\"val_score_out_dist: {np.round(val_score_out_dist,2)}\")\n",
    "            #print(f\"wp infractions in dist: {wp_infractions_in_dist}, out dist: {wp_infractions_out_dist}\")\n",
    "            \n",
    "            \"\"\"wandb.log({\"val score indist\":val_score_in_dist, \n",
    "                       #\"val score outdist\":val_score_out_dist,\n",
    "                       \"collisions indist\":collisions_in_dist, \n",
    "                       #\"collisions outdist\":collisions_out_dist,\n",
    "                        #\"wp infractions indist\":wp_infractions_in_dist, \n",
    "                       #\"wp infractions outdist\":wp_infractions_out_dist,\n",
    "                        \"stops indist\":stops_in, \n",
    "                       #\"stops outdist\":stops_out\n",
    "                      })\"\"\"\n",
    "            \n",
    "        t1 = t2\n",
    "        log_counter+=1\n",
    "    \n",
    "    loss = np.array(epoch_loss).mean()\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation took 1 seconds\n",
      "validation took 2 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "validation took 16 seconds\n",
      "validation took 17 seconds\n",
      "val score in dist: 0.41\n",
      "val_score_out_dist: 0.2\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.29 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.29 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.31 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.124\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.32 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.45 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.39 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0891\n",
      "\n",
      "validation took 17 seconds\n",
      "validation took 17 seconds\n",
      "val score in dist: 0.82\n",
      "val_score_out_dist: 0.25\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.68 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.3 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.29 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0794\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.31 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.28 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.25 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.28 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0662\n",
      "\n",
      "validation took 16 seconds\n",
      "validation took 17 seconds\n",
      "val score in dist: 0.67\n",
      "val_score_out_dist: 0.16\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.31 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.43 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0791\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.48 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.25 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.1067\n",
      "\n",
      "validation took 16 seconds\n",
      "validation took 17 seconds\n",
      "val score in dist: 0.85\n",
      "val_score_out_dist: 0.19\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.42 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.24 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.28 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.28 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0698\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.28 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.32 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.45 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0639\n",
      "\n",
      "validation took 16 seconds\n",
      "validation took 17 seconds\n",
      "val score in dist: 0.81\n",
      "val_score_out_dist: 0.21\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.33 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.29 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.23 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0498\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.29 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.23 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0622\n",
      "\n",
      "validation took 16 seconds\n",
      "validation took 17 seconds\n",
      "val score in dist: 0.65\n",
      "val_score_out_dist: 0.22\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.29 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.4 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.4 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.087\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.31 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.28 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.25 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0464\n",
      "\n",
      "validation took 16 seconds\n",
      "validation took 17 seconds\n",
      "val score in dist: 0.93\n",
      "val_score_out_dist: 0.23\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.25 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.29 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0494\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.36 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.31 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.41 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.38 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0986\n",
      "\n",
      "validation took 16 seconds\n",
      "validation took 17 seconds\n",
      "val score in dist: 0.88\n",
      "val_score_out_dist: 0.24\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.32 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.25 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.27 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0508\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.29 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.25 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.26 seconds\n",
      "Queueing chunk of size torch.Size([200, 144, 3, 64, 64]) took 1.28 seconds\n",
      "Done with chunk. Training took 5 seconds. Chunk loss was 0.0373\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4c0aa5b2ebb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-92bc0833ed07>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mval_cadence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mval_score_in_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollisions_in_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwp_infractions_in_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstops_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_distribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_training_wheels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mval_score_in_dist\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mautopilot_score_baseline_in_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#collisions_in_dist /= autopilot_collisions_in_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-31a998415bb7>\u001b[0m in \u001b[0;36mtestdrive\u001b[0;34m(in_distribution, calibrate, use_training_wheels)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautopilot_control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfront\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/procgen/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/carlita/train_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, aux, hidden, return_salmap, register_activations)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Why was this activation missing?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_2b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m#x = self.pooler(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/procgen/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/procgen/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/procgen/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
