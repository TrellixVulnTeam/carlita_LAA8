{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import threading\n",
    "\n",
    "from train_utils import *\n",
    "\n",
    "import gym3\n",
    "from procgen import ProcgenGym3Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_levels = 100_000 #500 #1500\n",
    "train_start_level = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building procgen...done\n"
     ]
    }
   ],
   "source": [
    "bs = 144 \n",
    "\n",
    "env = ProcgenGym3Env(num=bs, env_name=\"testgame\", num_levels=train_num_levels, start_level=train_start_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 195 ms, total: 4.89 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s = np.array([[.0,.0] for _ in range(bs)], dtype=np.float32)\n",
    "\n",
    "seq_len = 200\n",
    "\n",
    "for i in range(seq_len):\n",
    "    env.act(s)\n",
    "    rew, obs, first = env.observe()\n",
    "    img = obs['rgb']\n",
    "    info = env.get_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 15.03 seconds\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(env=env, bs=bs, seq_len=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "front, aux, target = dataloader.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([800, 144, 3, 64, 64]),\n",
       " torch.Size([800, 144, 5]),\n",
       " torch.Size([800, 144, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 17.57 seconds\n"
     ]
    }
   ],
   "source": [
    "front.shape, aux.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = VizCNN(use_rnn=False).to(device);\n",
    "\n",
    "#m = EfficientNet.from_pretrained('efficientnet-b4', in_channels=3, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VizCNN(\n",
       "  (pooler): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (act): ReLU()\n",
       "  (conv_1a): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2a): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2b): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_3a): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_4a): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (fc0): Linear(in_features=5189, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.load_state_dict(torch.load(\"m.torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3192.834"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([torch.numel(p) for p in m.parameters()]) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hidden = get_hidden(bs)\n",
    "    out, hidden = m(front[:6].to(device), aux[:6].to(device), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del front, aux, target, out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdrive(in_distribution=True, calibrate=False, use_training_wheels=False):\n",
    "    \n",
    "    TRAINING_WHEELS_WINDOW = 30\n",
    "    \n",
    "    t1 = time.time()\n",
    "    m.eval()\n",
    "    seq_len = 100 #0\n",
    "    n_val = 100\n",
    "    val_env = ProcgenGym3Env(num=n_val, \n",
    "                            env_name=\"testgame\", \n",
    "                            num_levels=train_num_levels, \n",
    "                            start_level=train_start_level if in_distribution else train_start_level+train_num_levels)\n",
    "    \n",
    "    s = np.array([[.0,.0] for _ in range(n_val)], dtype=np.float32)\n",
    "    reward = 0\n",
    "    num_collisions = 0\n",
    "    wp_infractions = 0\n",
    "    successful_stops = 0\n",
    "    \n",
    "    hidden = get_hidden(n_val)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(seq_len):\n",
    "            val_env.act(s)\n",
    "            rew, obs, first = val_env.observe()\n",
    "            reward += rew.sum()\n",
    "            img = obs['rgb']\n",
    "            info = val_env.get_info()\n",
    "            num_collisions += np.array([e['collision'] for e in info]).sum()\n",
    "            wp_infractions += np.array([e['waypoint_infraction'] for e in info]).sum()\n",
    "            successful_stops += np.array([e['successful_stop'] for e in info]).sum()\n",
    "            \n",
    "            autopilot_control = np.array([[e[\"autopilot_\"+c] for c in control_properties] for e in info])\n",
    "            \n",
    "            aux = np.array([[e[a] for a in aux_properties] for e in info])\n",
    "\n",
    "            front = torch.from_numpy(img.astype(np.float32)/255.).unsqueeze(0).permute(0,1,4,2,3).to(device)\n",
    "            \n",
    "            aux = torch.from_numpy(aux.astype(np.float32)).unsqueeze(0).to(device)\n",
    "            \n",
    "            if calibrate:\n",
    "                s = autopilot_control\n",
    "            else:\n",
    "                out, hidden = m(front, aux, hidden)\n",
    "                s = out.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "                s = np.clip(s, -5., 5.)\n",
    "                \n",
    "            if use_training_wheels and i < TRAINING_WHEELS_WINDOW:\n",
    "                s = autopilot_control\n",
    "        \n",
    "\n",
    "    reward /= (n_val*seq_len)\n",
    "    num_collisions /= (n_val*seq_len)\n",
    "    wp_infractions /= (n_val*seq_len)\n",
    "    successful_stops /= (n_val*seq_len)\n",
    "    \n",
    "    val_env.close()\n",
    "    m.train()\n",
    "    print(f\"validation took {round(time.time()-t1)} seconds\")\n",
    "    return reward, num_collisions, wp_infractions, successful_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdrive(in_distribution=True, calibrate=False, use_training_wheels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss().cuda()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "opt = torch.optim.Adam(m.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wandb.init(project=\"carlita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.watch(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_epoch(train=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Caching baseline 'perfect' scores for val use. A bit awkward placement\n",
    "    autopilot_score_baseline_in_dist, autopilot_collisions_in_dist, _, ap_successful_stops_in = testdrive(in_distribution=True, calibrate=True)\n",
    "    #autopilot_score_baseline_out_dist, autopilot_collisions_out_dist, _, ap_successful_stops_out = testdrive(in_distribution=False, calibrate=True)\n",
    "    \n",
    "    m.train(train)\n",
    "    t1 = time.time()\n",
    "    epoch_loss, preds = [], []\n",
    "    #bs = random.choice(list(bs_bptt_lookup.keys()))\n",
    "    bptt = 1 #32 #random.choice([64, 72, 80, 88]) # increasing for 32x32 data #bs_bptt_lookup[bs]\n",
    "    \n",
    "    val_cadence = 8\n",
    "    log_cadence = 4\n",
    "    \n",
    "    global dataloader, bs\n",
    "    #dataloader = DataLoader(bs=bs) \n",
    "    log_counter = 0\n",
    "    \n",
    "    #hidden_reset_counter = 0\n",
    "    #hidden_reset_cadence = 8\n",
    "    \n",
    "    while True:\n",
    "        chunk = dataloader.get_chunk() # Returns a chunk instantly, begins queuing up another chunk async\n",
    "        if not chunk: break\n",
    "        front_container, aux_container, target_container = chunk\n",
    "        chunk_len, bs, _, _, _ = front_container.shape\n",
    "        len_ix = 0\n",
    "        chunk_loss = []\n",
    "        \n",
    "        hidden = get_hidden(bs) # Resetting each chunk, ie each 800 steps or so\n",
    "        \n",
    "        while len_ix < chunk_len:\n",
    "            \n",
    "            #if hidden_reset_counter % hidden_reset_cadence == 0:\n",
    "            #    hidden = get_hidden(bs)\n",
    "            #    print(\"Resetting hidden\")\n",
    "            #hidden_reset_counter+=1\n",
    "                \n",
    "            front = front_container[len_ix:len_ix+bptt, :, :, :, :].to(device).half()\n",
    "            aux = aux_container[len_ix:len_ix+bptt, :, :].to(device).half();\n",
    "            target = target_container[len_ix:len_ix+bptt, :, :].to(device).half()\n",
    "            len_ix += bptt\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred, hidden = m(front, aux, hidden)\n",
    "                \n",
    "            loss = loss_fn(target, pred); \n",
    "            chunk_loss.append(loss.item())\n",
    "                \n",
    "            if train:\n",
    "                # Scales the loss, and calls backward() to create scaled gradients \n",
    "                scaler.scale(loss).backward() \n",
    "                \n",
    "                # Unscales the gradients of optimizer's assigned params in-place\n",
    "                scaler.unscale_(opt)\n",
    "                # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                torch.nn.utils.clip_grad_norm_(m.parameters(), 5.)\n",
    "\n",
    "        \n",
    "                # Unscales gradients and calls or skips optimizer.step() \n",
    "                scaler.step(opt) \n",
    "                # Updates the scale for next iteration \n",
    "                scaler.update() \n",
    "                opt.zero_grad()\n",
    "                \n",
    "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "\n",
    "        # Save and report at end of each chunk\n",
    "        t2 = time.time()\n",
    "        chunk_loss = np.round(np.array(chunk_loss).mean(), 4)\n",
    "        epoch_loss.append(chunk_loss)\n",
    "        total_seconds = round(t2 - t1)\n",
    "        \n",
    "        if train and log_counter % log_cadence == 0 and log_counter>1: \n",
    "            \n",
    "            current_time = time.time()\n",
    "            torch.save(m.state_dict(), 'm.torch')\n",
    "            \"\"\"wandb.log({\"Chunk Loss\": chunk_loss, \n",
    "                       \"Seconds per iter\":total_seconds, \n",
    "                       'LR':opt.param_groups[0]['lr'],\n",
    "                       \"Total time (min)\":round((time.time()-start_time) / 60)\n",
    "                      })\"\"\"\n",
    "            print(f'Done with chunk. Training took {total_seconds} seconds. Chunk loss was {chunk_loss}\\n')\n",
    "            \n",
    "        if log_counter % val_cadence == 0:\n",
    "            val_score_in_dist, collisions_in_dist, wp_infractions_in_dist, stops_in = testdrive(in_distribution=True, use_training_wheels=True) \n",
    "            val_score_in_dist /= autopilot_score_baseline_in_dist\n",
    "            #collisions_in_dist /= autopilot_collisions_in_dist\n",
    "            #stops_in /= ap_successful_stops_in\n",
    "            \n",
    "            #val_score_out_dist, collisions_out_dist, wp_infractions_out_dist, stops_out = testdrive(in_distribution=False, use_training_wheels=True)\n",
    "            #val_score_out_dist /= autopilot_score_baseline_out_dist\n",
    "            #collisions_out_dist /= autopilot_collisions_out_dist\n",
    "            #stops_out /= ap_successful_stops_out\n",
    "            \n",
    "            print(f\"val score in dist: {np.round(val_score_in_dist,2)}\")\n",
    "            print(f\"collisions in dist: {np.round(collisions_in_dist,2)}\")\n",
    "            #print(f\"wp infractions in dist: {wp_infractions_in_dist}, out dist: {wp_infractions_out_dist}\")\n",
    "            \n",
    "            \"\"\"wandb.log({\"val score indist\":val_score_in_dist, \n",
    "                       #\"val score outdist\":val_score_out_dist,\n",
    "                       \"collisions indist\":collisions_in_dist, \n",
    "                       #\"collisions outdist\":collisions_out_dist,\n",
    "                        #\"wp infractions indist\":wp_infractions_in_dist, \n",
    "                       #\"wp infractions outdist\":wp_infractions_out_dist,\n",
    "                        \"stops indist\":stops_in, \n",
    "                       #\"stops outdist\":stops_out\n",
    "                      })\"\"\"\n",
    "            \n",
    "        t1 = t2\n",
    "        log_counter+=1\n",
    "    \n",
    "    loss = np.array(epoch_loss).mean()\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation took 3 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.15 seconds\n",
      "validation took 8 seconds\n",
      "val score in dist: 0.09\n",
      "collisions in dist: 0.0\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.09 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.11 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.48 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 3.87 seconds\n",
      "Done with chunk. Training took 24 seconds. Chunk loss was 0.1459\n",
      "\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 3.87 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.48 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 3.86 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 3.92 seconds\n",
      "Done with chunk. Training took 24 seconds. Chunk loss was 0.0871\n",
      "\n",
      "validation took 8 seconds\n",
      "val score in dist: 0.27\n",
      "collisions in dist: 0.0\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.54 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 3.86 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 3.89 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.39 seconds\n",
      "Done with chunk. Training took 24 seconds. Chunk loss was 0.0807\n",
      "\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 3.82 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.14 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.51 seconds\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 3.89 seconds\n",
      "Done with chunk. Training took 24 seconds. Chunk loss was 0.0861\n",
      "\n",
      "validation took 8 seconds\n",
      "val score in dist: 0.79\n",
      "collisions in dist: 0.0\n",
      "Queueing chunk of size torch.Size([800, 144, 3, 64, 64]) took 4.08 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4c0aa5b2ebb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-3f554ed17369>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfront\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/procgen/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/carlita/train_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, aux, hidden, return_salmap, register_activations)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregister_activations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0msalmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
