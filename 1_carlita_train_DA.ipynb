{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import threading\n",
    "\n",
    "from train_utils import *\n",
    "\n",
    "import gym3\n",
    "from procgen import ProcgenGym3Env\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltoi = lambda l: int(''.join([str(n) for n in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_levels = 100_000 #500 #1500\n",
    "train_start_level = 0\n",
    "\n",
    "all_color_themes = [0,1,2,3,4,5,6,7]\n",
    "all_road_themes = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "color_themes_outdist = all_color_themes #[0,1]\n",
    "color_themes_road_outdist = all_road_themes #[2,3]\n",
    "outdist_backnoise = 100\n",
    "\n",
    "\n",
    "color_themes_outdist = ltoi(color_themes_outdist)\n",
    "color_themes_road_outdist = ltoi(color_themes_road_outdist)\n",
    "\n",
    "color_themes_indist = color_themes_outdist #ltoi([n for n in all_color_themes if n not in color_themes_outdist])\n",
    "color_themes_road_indist = color_themes_road_outdist #ltoi([n for n in all_color_themes if n not in color_themes_road_outdist])\n",
    "indist_backnoise = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building procgen...done\n"
     ]
    }
   ],
   "source": [
    "bs = 64 \n",
    "\n",
    "env = ProcgenGym3Env(num=bs, env_name=\"testgame\", num_levels=train_num_levels, start_level=train_start_level,\n",
    "                    color_theme=color_themes_indist, color_theme_road=color_themes_road_indist,\n",
    "                    background_noise_level=indist_backnoise)\n",
    "\n",
    "env_outdist = ProcgenGym3Env(num=bs, env_name=\"testgame\", num_levels=train_num_levels, start_level=train_start_level,\n",
    "                    color_theme=color_themes_outdist, color_theme_road=color_themes_road_outdist,\n",
    "                    background_noise_level=outdist_backnoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 s, sys: 89 ms, total: 2.41 s\n",
      "Wall time: 572 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s = np.array([[.0,.0] for _ in range(bs)], dtype=np.float32)\n",
    "\n",
    "seq_len = 200\n",
    "\n",
    "for i in range(seq_len):\n",
    "    env_indist.act(s)\n",
    "    rew, obs, first = env_indist.observe()\n",
    "    img = obs['rgb']\n",
    "    info = env_indist.get_info()\n",
    "plt.imshow(img[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "s = np.array([[.0,.0] for _ in range(bs)], dtype=np.float32)\n",
    "\n",
    "seq_len = 200\n",
    "\n",
    "for i in range(seq_len):\n",
    "    env_outdist.act(s)\n",
    "    rew, obs, first = env_outdist.observe()\n",
    "    img = obs['rgb']\n",
    "    info = env_outdist.get_info()\n",
    "plt.imshow(img[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.36 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.35 seconds\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(env=env, bs=bs, seq_len=200)\n",
    "dataloader_outdist = DataLoader(env=env_outdist, bs=bs, seq_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "front, aux, target = dataloader.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 64, 3, 64, 64]),\n",
       " torch.Size([200, 64, 5]),\n",
       " torch.Size([200, 64, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front.shape, aux.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.36 seconds\n"
     ]
    }
   ],
   "source": [
    "m = VizCNN(use_rnn=False).to(device);\n",
    "\n",
    "#m = EfficientNet.from_pretrained('efficientnet-b4', in_channels=3, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VizCNN(\n",
       "  (pooler): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (act): ReLU()\n",
       "  (conv_1a): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn1_): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2a): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2a_): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2b): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2b_): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_3a): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3_): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_4a): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4_): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (fc0): Linear(in_features=5189, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.load_state_dict(torch.load(\"m.torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3193.314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([torch.numel(p) for p in m.parameters()]) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hidden = get_hidden(bs)\n",
    "    out, hidden = m(front[:6].to(device), aux[:6].to(device), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del front, aux, target, out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for implementing data augmentation\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "deg_to_rad = lambda x: x*0.0174533\n",
    "crop = transforms.CenterCrop(48)\n",
    "resize = transforms.Resize(64)\n",
    "color_jitter = transforms.ColorJitter(brightness=.5, contrast=.5, saturation=.5, hue=.5)\n",
    "\n",
    "def get_rotated_view(front, aux, rotation):\n",
    "    front = front.clone()\n",
    "    SEQ_LEN, BS, C, H, W = front.shape\n",
    "    ff = front.reshape(SEQ_LEN*BS, C, H, W)\n",
    "    ff = transforms.functional.rotate(ff, rotation)\n",
    "    ff = crop(ff)\n",
    "    ff = resize(ff)\n",
    "    ##ff = color_jitter(ff)\n",
    "    ff = ff.reshape(SEQ_LEN, BS, C, H, W)\n",
    "    _aux = aux.clone()\n",
    "    _aux[:,:,0] -= deg_to_rad(rotation)\n",
    "    return ff, _aux\n",
    "\n",
    "\n",
    "def get_output_shaping_loss(pred): #REVISIT THIS. should not be using these on rotation without more thought.\n",
    "    target_mean, target_std = 0, .55\n",
    "    steer_pred_mean, steer_pred_std = pred[:,:,0].flatten().mean(), pred[:,:,0].flatten().std()\n",
    "    mse = lambda x1, x2: (x1-x2)**2\n",
    "    l = mse(target_std, steer_pred_std) + mse(target_mean, steer_pred_mean)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdrive(in_distribution=True, calibrate=False, use_training_wheels=False):\n",
    "    \n",
    "    TRAINING_WHEELS_WINDOW = 10\n",
    "    \n",
    "    t1 = time.time()\n",
    "    m.eval()\n",
    "    seq_len = 300\n",
    "    n_val = 100\n",
    "    val_env = ProcgenGym3Env(num=n_val, \n",
    "                            env_name=\"testgame\", \n",
    "                            num_levels=train_num_levels, \n",
    "                            start_level=train_start_level if in_distribution else train_start_level+train_num_levels,\n",
    "                            color_theme=color_themes_indist if in_distribution else color_themes_outdist,\n",
    "                            color_theme_road=color_themes_road_indist if in_distribution else color_themes_road_outdist,\n",
    "                            background_noise_level = 0 if in_distribution else 100\n",
    "                            )\n",
    "    \n",
    "    s = np.array([[.0,.0] for _ in range(n_val)], dtype=np.float32)\n",
    "    reward = 0\n",
    "    num_collisions = 0\n",
    "    wp_infractions = 0\n",
    "    successful_stops = 0\n",
    "    \n",
    "    hidden = get_hidden(n_val)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(seq_len):\n",
    "            val_env.act(s)\n",
    "            rew, obs, first = val_env.observe()\n",
    "            reward += rew.sum()\n",
    "            img = obs['rgb']\n",
    "            info = val_env.get_info()\n",
    "            num_collisions += np.array([e['collision'] for e in info]).sum()\n",
    "            wp_infractions += np.array([e['waypoint_infraction'] for e in info]).sum()\n",
    "            successful_stops += np.array([e['successful_stop'] for e in info]).sum()\n",
    "            \n",
    "            autopilot_control = np.array([[e[\"autopilot_\"+c] for c in control_properties] for e in info])\n",
    "            \n",
    "            aux = np.array([[e[a] for a in aux_properties] for e in info])\n",
    "\n",
    "            front = torch.from_numpy(img.astype(np.float32)/255.).unsqueeze(0).permute(0,1,4,2,3).to(device)\n",
    "            \n",
    "            aux = torch.from_numpy(aux.astype(np.float32)).unsqueeze(0).to(device)\n",
    "            \n",
    "            front, aux = get_rotated_view(front, aux, 0)\n",
    "            \n",
    "            if calibrate:\n",
    "                s = autopilot_control\n",
    "            else:\n",
    "                out, hidden = m(front, aux, hidden, is_src_domain=in_distribution)\n",
    "                s = out.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "                s = np.clip(s, -5., 5.)\n",
    "                \n",
    "            if use_training_wheels and i < TRAINING_WHEELS_WINDOW:\n",
    "                s = autopilot_control\n",
    "        \n",
    "\n",
    "    reward /= (n_val*seq_len)\n",
    "    num_collisions /= (n_val*seq_len)\n",
    "    wp_infractions /= (n_val*seq_len)\n",
    "    successful_stops /= (n_val*seq_len)\n",
    "    \n",
    "    val_env.close()\n",
    "    m.train()\n",
    "    print(f\"validation took {round(time.time()-t1)} seconds\")\n",
    "    return reward, num_collisions, wp_infractions, successful_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation took 13 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05196666666666667, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdrive(in_distribution=False, calibrate=False, use_training_wheels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss().cuda()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "opt = torch.optim.Adam(m.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wandb.init(project=\"carlita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.watch(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_epoch(train=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Caching baseline 'perfect' scores for val use. A bit awkward placement\n",
    "    autopilot_score_baseline_in_dist, autopilot_collisions_in_dist, _, ap_successful_stops_in = testdrive(in_distribution=True, calibrate=True)\n",
    "    autopilot_score_baseline_out_dist, autopilot_collisions_out_dist, _, ap_successful_stops_out = testdrive(in_distribution=False, calibrate=True)\n",
    "    \n",
    "    m.train(train)\n",
    "    t1 = time.time()\n",
    "    epoch_loss, preds = [], []\n",
    "    #bs = random.choice(list(bs_bptt_lookup.keys()))\n",
    "    bptt = 1 #32 #random.choice([64, 72, 80, 88]) # increasing for 32x32 data #bs_bptt_lookup[bs]\n",
    "    \n",
    "    val_cadence = 8\n",
    "    log_cadence = 1\n",
    "    \n",
    "    global dataloader,dataloader_outdist, bs\n",
    "    log_counter = 0\n",
    "    \n",
    "    logger = Logger()\n",
    "    \n",
    "    while True:\n",
    "        chunk = dataloader.get_chunk()\n",
    "        if not chunk: break\n",
    "        front_container, aux_container, target_container = chunk\n",
    "        chunk_len, bs, _, _, _ = front_container.shape\n",
    "        len_ix = 0\n",
    "        chunk_loss = []\n",
    "        \n",
    "        chunk_outdist = dataloader_outdist.get_chunk()\n",
    "        front_container_outdist, aux_container_outdist, _ = chunk_outdist\n",
    "        \n",
    "        hidden = get_hidden(bs) # Resetting each chunk, ie each 800 steps or so\n",
    "        \n",
    "        while len_ix < chunk_len:\n",
    "                \n",
    "            #####################\n",
    "            # Supervised loss on indist\n",
    "            \n",
    "            front = front_container[len_ix:len_ix+bptt, :, :, :, :].to(device).half()\n",
    "            aux = aux_container[len_ix:len_ix+bptt, :, :].to(device).half();\n",
    "            front, aux = get_rotated_view(front, aux, 0)\n",
    "            \n",
    "            target = target_container[len_ix:len_ix+bptt, :, :].to(device).half()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred, hidden = m(front, aux, hidden, is_src_domain=True)\n",
    "                \n",
    "            supervised_loss = loss_fn(target, pred); \n",
    "            chunk_loss.append(supervised_loss.item())\n",
    "            \n",
    "            #####################\n",
    "            # Unsupervised loss on outdist\n",
    "            front_outdist = front_container_outdist[len_ix:len_ix+bptt, :, :, :, :].to(device).half()\n",
    "            aux_outdist = aux_container_outdist[len_ix:len_ix+bptt, :, :].to(device).half();\n",
    "            \n",
    "            rotation = random.uniform(2,12)\n",
    "\n",
    "            front_base, aux_base = get_rotated_view(front_outdist, aux_outdist, 0)\n",
    "            front_flip = front_base.flip(-1)\n",
    "            aux_flip = aux_base.clone(); aux_flip[:,:,0]*=-1\n",
    "            front_rot_pos, aux_rot_pos = get_rotated_view(front_outdist, aux_outdist, rotation)\n",
    "            front_rot_neg, aux_rot_neg = get_rotated_view(front_outdist, aux_outdist, -rotation)\n",
    "            front_rot_pos_2, aux_rot_pos_2 = get_rotated_view(front_outdist, aux_outdist, rotation*2)\n",
    "            front_rot_neg_2, aux_rot_neg_2 = get_rotated_view(front_outdist, aux_outdist, -rotation*2)\n",
    "\n",
    "            front_all = torch.cat([\n",
    "                front_base,\n",
    "                front_flip,\n",
    "                front_rot_pos,\n",
    "                front_rot_neg,\n",
    "                front_rot_pos_2,\n",
    "                front_rot_neg_2\n",
    "            ], dim=0)\n",
    "\n",
    "            aux_all = torch.cat([\n",
    "                aux_base,\n",
    "                aux_flip,\n",
    "                aux_rot_pos,\n",
    "                aux_rot_neg,\n",
    "                aux_rot_pos_2,\n",
    "                aux_rot_neg_2,\n",
    "            ], dim=0)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_all, _ = m(front_all, aux_all, '', is_src_domain=False)\n",
    "\n",
    "            pred_base, pred_flip, pred_rot_pos, pred_rot_neg, pred_rot_pos_2, pred_rot_neg_2 = torch.split(pred_all, len(front_base), dim=0)\n",
    "            \n",
    "            output_shaping_loss = 0\n",
    "            output_shaping_loss += get_output_shaping_loss(torch.cat([pred_flip, pred_base], dim=0))\n",
    "            \n",
    "            pred_base = pred_base.detach()\n",
    "\n",
    "            # flip\n",
    "            flip_loss = loss_fn(pred_base[:,:,0], pred_flip[:,:,0]*-1)\n",
    "\n",
    "            # Rotation consistency I\n",
    "            rotation_loss = 0\n",
    "\n",
    "            diff_pos = pred_rot_pos[:,:,0] - pred_base[:,:,0]\n",
    "            diff_target = -torch.ones_like(diff_pos) * deg_to_rad(rotation)*1.27\n",
    "            rotation_loss += loss_fn(diff_pos, diff_target)\n",
    "\n",
    "            diff_neg = pred_rot_neg[:,:,0] - pred_base[:,:,0]\n",
    "            diff_target = -torch.ones_like(diff_neg) * deg_to_rad(-rotation)*1.27\n",
    "            rotation_loss += loss_fn(diff_neg, diff_target)\n",
    "            \n",
    "            # Rotation consistency II\n",
    "            rotation_loss_2 = 0\n",
    "            rotation_loss_2 += loss_fn((diff_pos*2).detach(), pred_rot_pos_2[:,:,0]-pred_base[:,:,0])\n",
    "            rotation_loss_2 += loss_fn((diff_neg*2).detach(), pred_rot_neg_2[:,:,0]-pred_base[:,:,0])\n",
    "            \n",
    "            ##################\n",
    "            b = 1\n",
    "            flip_loss/=b\n",
    "            rotation_loss/=b\n",
    "            rotation_loss_2/=b\n",
    "            output_shaping_loss/=b\n",
    "            \n",
    "            #loss = flip_loss + rotation_loss + rotation_loss_2 + supervised_loss + output_shaping_loss\n",
    "            loss = supervised_loss\n",
    "            logger.log({\n",
    "                \"supervised_loss\":supervised_loss.item(),\n",
    "                \"rotation_loss\":rotation_loss.item(),\n",
    "                \"rotation_loss_2\":rotation_loss_2.item(),\n",
    "                \"flip_loss\":flip_loss.item(),\n",
    "                \"output_shaping_loss\":output_shaping_loss.item(),\n",
    "            })\n",
    "                \n",
    "            len_ix += bptt*4\n",
    "            \n",
    "            if train:\n",
    "                # Scales the loss, and calls backward() to create scaled gradients \n",
    "                scaler.scale(loss).backward() \n",
    "                \n",
    "                # Unscales the gradients of optimizer's assigned params in-place\n",
    "                scaler.unscale_(opt)\n",
    "                # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                torch.nn.utils.clip_grad_norm_(m.parameters(), 5.)\n",
    "        \n",
    "                # Unscales gradients and calls or skips optimizer.step() \n",
    "                scaler.step(opt) \n",
    "                # Updates the scale for next iteration \n",
    "                scaler.update() \n",
    "                opt.zero_grad()\n",
    "                \n",
    "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "\n",
    "        # Save and report at end of each chunk\n",
    "        t2 = time.time()\n",
    "        chunk_loss = np.round(np.array(chunk_loss).mean(), 4)\n",
    "        epoch_loss.append(chunk_loss)\n",
    "        total_seconds = round(t2 - t1)\n",
    "        \n",
    "        if train and log_counter % log_cadence == 0 and log_counter>1: \n",
    "            print(logger.finish())\n",
    "            current_time = time.time()\n",
    "            torch.save(m.state_dict(), 'm.torch')\n",
    "            print(f'Done with chunk. Training took {total_seconds} seconds. Chunk loss was {chunk_loss}\\n')\n",
    "            \n",
    "        if log_counter % val_cadence == 0:\n",
    "            val_score_in_dist, collisions_in_dist, wp_infractions_in_dist, stops_in = testdrive(in_distribution=True, use_training_wheels=False) \n",
    "            val_score_in_dist /= autopilot_score_baseline_in_dist\n",
    "            #collisions_in_dist /= autopilot_collisions_in_dist\n",
    "            #stops_in /= ap_successful_stops_in\n",
    "            \n",
    "            val_score_out_dist, collisions_out_dist, wp_infractions_out_dist, stops_out = testdrive(in_distribution=False, use_training_wheels=True)\n",
    "            val_score_out_dist /= autopilot_score_baseline_out_dist\n",
    "            #collisions_out_dist /= autopilot_collisions_out_dist\n",
    "            #stops_out /= ap_successful_stops_out\n",
    "            \n",
    "            logger.log({\n",
    "                \"score_indist\":np.round(val_score_in_dist,2),\n",
    "                \"score_outdist\":np.round(val_score_out_dist,2)\n",
    "            })\n",
    "            stats = logger.finish()\n",
    "            print(stats)\n",
    "            \n",
    "        t1 = t2\n",
    "        log_counter+=1\n",
    "    \n",
    "    loss = np.array(epoch_loss).mean()\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation took 1 seconds\n",
      "validation took 1 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'supervised_loss': 0.39925, 'rotation_loss': 0.08645, 'rotation_loss_2': 0.07104, 'flip_loss': 0.42531, 'output_shaping_loss': 0.17522, 'score_indist': 0.13, 'score_outdist': 0.16}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.68 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.3261, 'rotation_loss': 0.06644, 'rotation_loss_2': 0.03788, 'flip_loss': 0.12354, 'output_shaping_loss': 0.21934}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.3552\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.26085, 'rotation_loss': 0.06538, 'rotation_loss_2': 0.02446, 'flip_loss': 0.09281, 'output_shaping_loss': 0.18826}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.2609\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.21547, 'rotation_loss': 0.06529, 'rotation_loss_2': 0.04349, 'flip_loss': 0.21339, 'output_shaping_loss': 0.09599}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.2155\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.23031, 'rotation_loss': 0.09048, 'rotation_loss_2': 0.07257, 'flip_loss': 0.43013, 'output_shaping_loss': 0.07816}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.2303\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.17404, 'rotation_loss': 0.0886, 'rotation_loss_2': 0.07019, 'flip_loss': 0.38575, 'output_shaping_loss': 0.04511}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.174\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.24091, 'rotation_loss': 0.10084, 'rotation_loss_2': 0.1061, 'flip_loss': 0.76141, 'output_shaping_loss': 0.10733}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.2409\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.17436, 'rotation_loss': 0.10727, 'rotation_loss_2': 0.14841, 'flip_loss': 0.95632, 'output_shaping_loss': 0.10048}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1744\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.32, 'score_outdist': 0.23}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.72 seconds\n",
      "{'supervised_loss': 0.1881, 'rotation_loss': 0.0933, 'rotation_loss_2': 0.12302, 'flip_loss': 0.77414, 'output_shaping_loss': 0.07028}\n",
      "Done with chunk. Training took 32 seconds. Chunk loss was 0.1881\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.51 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.48 seconds\n",
      "{'supervised_loss': 0.28563, 'rotation_loss': 0.10488, 'rotation_loss_2': 0.12169, 'flip_loss': 0.89662, 'output_shaping_loss': 0.08316}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.2856\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.72 seconds\n",
      "{'supervised_loss': 0.17741, 'rotation_loss': 0.12445, 'rotation_loss_2': 0.18847, 'flip_loss': 0.95924, 'output_shaping_loss': 0.08742}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1774\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.3439, 'rotation_loss': 0.08788, 'rotation_loss_2': 0.13056, 'flip_loss': 0.69041, 'output_shaping_loss': 0.09124}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.3439\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.15261, 'rotation_loss': 0.13588, 'rotation_loss_2': 0.23566, 'flip_loss': 0.86322, 'output_shaping_loss': 0.0581}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1526\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.13477, 'rotation_loss': 0.10568, 'rotation_loss_2': 0.2157, 'flip_loss': 0.82915, 'output_shaping_loss': 0.0799}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1348\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.12213, 'rotation_loss': 0.14246, 'rotation_loss_2': 0.2351, 'flip_loss': 1.0945, 'output_shaping_loss': 0.09518}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1221\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "{'supervised_loss': 0.12344, 'rotation_loss': 0.10323, 'rotation_loss_2': 0.19412, 'flip_loss': 0.96405, 'output_shaping_loss': 0.0729}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1234\n",
      "\n",
      "validation took 14 seconds\n",
      "validation took 14 seconds\n",
      "{'score_indist': 0.49, 'score_outdist': 0.4}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.09743, 'rotation_loss': 0.14195, 'rotation_loss_2': 0.25837, 'flip_loss': 0.87683, 'output_shaping_loss': 0.06249}\n",
      "Done with chunk. Training took 35 seconds. Chunk loss was 0.0974\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.14701, 'rotation_loss': 0.13333, 'rotation_loss_2': 0.29595, 'flip_loss': 1.13643, 'output_shaping_loss': 0.11381}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.147\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.13192, 'rotation_loss': 0.10991, 'rotation_loss_2': 0.28849, 'flip_loss': 1.11972, 'output_shaping_loss': 0.10481}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1319\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.72 seconds\n",
      "{'supervised_loss': 0.11479, 'rotation_loss': 0.14185, 'rotation_loss_2': 0.28265, 'flip_loss': 1.02667, 'output_shaping_loss': 0.09336}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1148\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.05 seconds\n",
      "{'supervised_loss': 0.16189, 'rotation_loss': 0.13206, 'rotation_loss_2': 0.24913, 'flip_loss': 0.71853, 'output_shaping_loss': 0.05345}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1619\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.1 seconds\n",
      "{'supervised_loss': 0.13819, 'rotation_loss': 0.08881, 'rotation_loss_2': 0.21106, 'flip_loss': 0.96189, 'output_shaping_loss': 0.10532}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.1382\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervised_loss': 0.11197, 'rotation_loss': 0.10542, 'rotation_loss_2': 0.25358, 'flip_loss': 1.10989, 'output_shaping_loss': 0.12249}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.112\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.09818, 'rotation_loss': 0.12387, 'rotation_loss_2': 0.32574, 'flip_loss': 1.4781, 'output_shaping_loss': 0.23263}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0982\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.49, 'score_outdist': 0.44}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.12686, 'rotation_loss': 0.14411, 'rotation_loss_2': 0.28569, 'flip_loss': 1.40507, 'output_shaping_loss': 0.21213}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.1269\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.1477, 'rotation_loss': 0.09433, 'rotation_loss_2': 0.2169, 'flip_loss': 1.01943, 'output_shaping_loss': 0.10591}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1477\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.08359, 'rotation_loss': 0.10932, 'rotation_loss_2': 0.22572, 'flip_loss': 1.2046, 'output_shaping_loss': 0.14414}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0836\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "{'supervised_loss': 0.08865, 'rotation_loss': 0.12703, 'rotation_loss_2': 0.26525, 'flip_loss': 1.8425, 'output_shaping_loss': 0.33245}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0886\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "{'supervised_loss': 0.13226, 'rotation_loss': 0.14878, 'rotation_loss_2': 0.30902, 'flip_loss': 1.70909, 'output_shaping_loss': 0.27393}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1323\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.06967, 'rotation_loss': 0.17404, 'rotation_loss_2': 0.38934, 'flip_loss': 1.60689, 'output_shaping_loss': 0.29134}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0697\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.07564, 'rotation_loss': 0.19447, 'rotation_loss_2': 0.38166, 'flip_loss': 2.03205, 'output_shaping_loss': 0.41069}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0756\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.69 seconds\n",
      "{'supervised_loss': 0.07766, 'rotation_loss': 0.23714, 'rotation_loss_2': 0.49889, 'flip_loss': 2.58266, 'output_shaping_loss': 0.53814}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0777\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.56, 'score_outdist': 0.46}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.3 seconds\n",
      "{'supervised_loss': 0.09445, 'rotation_loss': 0.14838, 'rotation_loss_2': 0.3393, 'flip_loss': 1.85219, 'output_shaping_loss': 0.37505}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0945\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.5 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.82 seconds\n",
      "{'supervised_loss': 0.12734, 'rotation_loss': 0.12453, 'rotation_loss_2': 0.26085, 'flip_loss': 1.09272, 'output_shaping_loss': 0.133}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1273\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.10696, 'rotation_loss': 0.19531, 'rotation_loss_2': 0.3737, 'flip_loss': 1.64658, 'output_shaping_loss': 0.27894}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.107\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.08562, 'rotation_loss': 0.15057, 'rotation_loss_2': 0.30413, 'flip_loss': 1.57511, 'output_shaping_loss': 0.25599}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0856\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.06919, 'rotation_loss': 0.16322, 'rotation_loss_2': 0.35924, 'flip_loss': 1.63971, 'output_shaping_loss': 0.27919}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0692\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.08785, 'rotation_loss': 0.1977, 'rotation_loss_2': 0.39818, 'flip_loss': 1.99155, 'output_shaping_loss': 0.36189}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0878\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.10704, 'rotation_loss': 0.19697, 'rotation_loss_2': 0.40775, 'flip_loss': 2.66967, 'output_shaping_loss': 0.58043}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.107\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.17034, 'rotation_loss': 0.13531, 'rotation_loss_2': 0.29121, 'flip_loss': 1.68747, 'output_shaping_loss': 0.30987}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1703\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.46, 'score_outdist': 0.34}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.11097, 'rotation_loss': 0.17453, 'rotation_loss_2': 0.32241, 'flip_loss': 1.27081, 'output_shaping_loss': 0.17253}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.111\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.13579, 'rotation_loss': 0.20685, 'rotation_loss_2': 0.44228, 'flip_loss': 1.89418, 'output_shaping_loss': 0.37418}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1358\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.11593, 'rotation_loss': 0.1971, 'rotation_loss_2': 0.43231, 'flip_loss': 1.69969, 'output_shaping_loss': 0.27432}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1159\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.9 seconds\n",
      "{'supervised_loss': 0.19666, 'rotation_loss': 0.21223, 'rotation_loss_2': 0.45364, 'flip_loss': 2.76398, 'output_shaping_loss': 0.55576}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1967\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.51 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.1 seconds\n",
      "{'supervised_loss': 0.16828, 'rotation_loss': 0.11408, 'rotation_loss_2': 0.23583, 'flip_loss': 2.95923, 'output_shaping_loss': 0.6417}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1683\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervised_loss': 0.11953, 'rotation_loss': 0.17619, 'rotation_loss_2': 0.37265, 'flip_loss': 3.06307, 'output_shaping_loss': 0.69199}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1195\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "{'supervised_loss': 0.08655, 'rotation_loss': 0.20211, 'rotation_loss_2': 0.38849, 'flip_loss': 2.43616, 'output_shaping_loss': 0.47576}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0866\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.17967, 'rotation_loss': 0.16551, 'rotation_loss_2': 0.35079, 'flip_loss': 1.84211, 'output_shaping_loss': 0.3448}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1797\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.42, 'score_outdist': 0.4}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.1356, 'rotation_loss': 0.15249, 'rotation_loss_2': 0.35212, 'flip_loss': 1.39983, 'output_shaping_loss': 0.21607}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.1356\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.10835, 'rotation_loss': 0.1805, 'rotation_loss_2': 0.33419, 'flip_loss': 1.46515, 'output_shaping_loss': 0.24742}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1084\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.063, 'rotation_loss': 0.21186, 'rotation_loss_2': 0.4389, 'flip_loss': 1.63577, 'output_shaping_loss': 0.34418}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.063\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.09099, 'rotation_loss': 0.1993, 'rotation_loss_2': 0.38627, 'flip_loss': 1.50667, 'output_shaping_loss': 0.26303}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.091\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.0719, 'rotation_loss': 0.21073, 'rotation_loss_2': 0.42779, 'flip_loss': 1.77533, 'output_shaping_loss': 0.36441}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0719\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.67 seconds\n",
      "{'supervised_loss': 0.07742, 'rotation_loss': 0.16218, 'rotation_loss_2': 0.31102, 'flip_loss': 2.01437, 'output_shaping_loss': 0.34456}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0774\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "{'supervised_loss': 0.14447, 'rotation_loss': 0.19603, 'rotation_loss_2': 0.37418, 'flip_loss': 3.69463, 'output_shaping_loss': 0.8185}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.1445\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.11 seconds\n",
      "{'supervised_loss': 0.09476, 'rotation_loss': 0.21357, 'rotation_loss_2': 0.38968, 'flip_loss': 1.45041, 'output_shaping_loss': 0.22292}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0948\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.5, 'score_outdist': 0.47}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.51 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.92 seconds\n",
      "{'supervised_loss': 0.13461, 'rotation_loss': 0.13349, 'rotation_loss_2': 0.25649, 'flip_loss': 1.67932, 'output_shaping_loss': 0.30569}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.1346\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.07675, 'rotation_loss': 0.15183, 'rotation_loss_2': 0.31408, 'flip_loss': 1.17154, 'output_shaping_loss': 0.17168}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0767\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.06694, 'rotation_loss': 0.2048, 'rotation_loss_2': 0.37823, 'flip_loss': 1.64679, 'output_shaping_loss': 0.3516}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0669\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.07921, 'rotation_loss': 0.26033, 'rotation_loss_2': 0.54902, 'flip_loss': 2.23034, 'output_shaping_loss': 0.51667}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0792\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.09534, 'rotation_loss': 0.15658, 'rotation_loss_2': 0.29167, 'flip_loss': 1.28637, 'output_shaping_loss': 0.20362}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0953\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.08886, 'rotation_loss': 0.17425, 'rotation_loss_2': 0.34382, 'flip_loss': 1.46855, 'output_shaping_loss': 0.2821}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0889\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.10704, 'rotation_loss': 0.18342, 'rotation_loss_2': 0.42103, 'flip_loss': 1.42927, 'output_shaping_loss': 0.25608}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.107\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.07857, 'rotation_loss': 0.23405, 'rotation_loss_2': 0.48593, 'flip_loss': 1.61613, 'output_shaping_loss': 0.30475}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0786\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.67, 'score_outdist': 0.57}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "{'supervised_loss': 0.07532, 'rotation_loss': 0.30001, 'rotation_loss_2': 0.64146, 'flip_loss': 1.95671, 'output_shaping_loss': 0.44278}\n",
      "Done with chunk. Training took 32 seconds. Chunk loss was 0.0753\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.68 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.72 seconds\n",
      "{'supervised_loss': 0.08622, 'rotation_loss': 0.24293, 'rotation_loss_2': 0.52896, 'flip_loss': 1.74046, 'output_shaping_loss': 0.33464}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0862\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.89 seconds\n",
      "{'supervised_loss': 0.1121, 'rotation_loss': 0.20318, 'rotation_loss_2': 0.49388, 'flip_loss': 1.41623, 'output_shaping_loss': 0.21191}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1121\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.05 seconds\n",
      "{'supervised_loss': 0.06603, 'rotation_loss': 0.21366, 'rotation_loss_2': 0.42641, 'flip_loss': 1.14721, 'output_shaping_loss': 0.17347}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.066\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.76 seconds\n",
      "{'supervised_loss': 0.10173, 'rotation_loss': 0.26708, 'rotation_loss_2': 0.54333, 'flip_loss': 1.38595, 'output_shaping_loss': 0.25844}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1017\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.06935, 'rotation_loss': 0.31152, 'rotation_loss_2': 0.61825, 'flip_loss': 1.56996, 'output_shaping_loss': 0.25658}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0694\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.09999, 'rotation_loss': 0.18275, 'rotation_loss_2': 0.33802, 'flip_loss': 1.34233, 'output_shaping_loss': 0.22879}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.08099, 'rotation_loss': 0.14147, 'rotation_loss_2': 0.34463, 'flip_loss': 1.28176, 'output_shaping_loss': 0.20316}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.081\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.58, 'score_outdist': 0.75}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.10574, 'rotation_loss': 0.14972, 'rotation_loss_2': 0.30322, 'flip_loss': 1.17004, 'output_shaping_loss': 0.20033}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.1057\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.07191, 'rotation_loss': 0.15576, 'rotation_loss_2': 0.29807, 'flip_loss': 1.17172, 'output_shaping_loss': 0.17108}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0719\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.06461, 'rotation_loss': 0.1348, 'rotation_loss_2': 0.28382, 'flip_loss': 0.81764, 'output_shaping_loss': 0.07927}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0646\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.06003, 'rotation_loss': 0.14064, 'rotation_loss_2': 0.34536, 'flip_loss': 0.9306, 'output_shaping_loss': 0.10847}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.06\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "{'supervised_loss': 0.05774, 'rotation_loss': 0.15957, 'rotation_loss_2': 0.32635, 'flip_loss': 0.9419, 'output_shaping_loss': 0.13494}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0577\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "{'supervised_loss': 0.06892, 'rotation_loss': 0.11789, 'rotation_loss_2': 0.25036, 'flip_loss': 0.94252, 'output_shaping_loss': 0.10526}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0689\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.93 seconds\n",
      "{'supervised_loss': 0.11149, 'rotation_loss': 0.10199, 'rotation_loss_2': 0.24103, 'flip_loss': 0.72256, 'output_shaping_loss': 0.051}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1115\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.5 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.93 seconds\n",
      "{'supervised_loss': 0.11337, 'rotation_loss': 0.19753, 'rotation_loss_2': 0.47555, 'flip_loss': 1.51966, 'output_shaping_loss': 0.26139}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1134\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.65, 'score_outdist': 0.41}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.11133, 'rotation_loss': 0.14049, 'rotation_loss_2': 0.29181, 'flip_loss': 1.05662, 'output_shaping_loss': 0.16666}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.1113\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.18567, 'rotation_loss': 0.14285, 'rotation_loss_2': 0.31319, 'flip_loss': 0.91398, 'output_shaping_loss': 0.06675}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1857\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "{'supervised_loss': 0.06716, 'rotation_loss': 0.18712, 'rotation_loss_2': 0.43136, 'flip_loss': 1.0903, 'output_shaping_loss': 0.06635}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0672\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.08991, 'rotation_loss': 0.15422, 'rotation_loss_2': 0.31214, 'flip_loss': 1.19563, 'output_shaping_loss': 0.16223}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0899\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.10757, 'rotation_loss': 0.15816, 'rotation_loss_2': 0.36764, 'flip_loss': 1.067, 'output_shaping_loss': 0.12745}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1076\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.06478, 'rotation_loss': 0.16273, 'rotation_loss_2': 0.34301, 'flip_loss': 1.19865, 'output_shaping_loss': 0.15151}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0648\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.08366, 'rotation_loss': 0.19733, 'rotation_loss_2': 0.4576, 'flip_loss': 1.47317, 'output_shaping_loss': 0.23238}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0837\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.07993, 'rotation_loss': 0.1973, 'rotation_loss_2': 0.42276, 'flip_loss': 1.29543, 'output_shaping_loss': 0.18597}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0799\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.72, 'score_outdist': 0.62}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "{'supervised_loss': 0.09511, 'rotation_loss': 0.24415, 'rotation_loss_2': 0.47348, 'flip_loss': 1.87305, 'output_shaping_loss': 0.31476}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0951\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.9 seconds\n",
      "{'supervised_loss': 0.12248, 'rotation_loss': 0.14062, 'rotation_loss_2': 0.28271, 'flip_loss': 0.89528, 'output_shaping_loss': 0.13104}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1225\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.93 seconds\n",
      "{'supervised_loss': 0.07508, 'rotation_loss': 0.16529, 'rotation_loss_2': 0.33899, 'flip_loss': 0.86261, 'output_shaping_loss': 0.09719}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0751\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.53 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.72 seconds\n",
      "{'supervised_loss': 0.11728, 'rotation_loss': 0.15786, 'rotation_loss_2': 0.35575, 'flip_loss': 1.28912, 'output_shaping_loss': 0.19189}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1173\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.0749, 'rotation_loss': 0.18888, 'rotation_loss_2': 0.43675, 'flip_loss': 1.07853, 'output_shaping_loss': 0.11544}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0749\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.06562, 'rotation_loss': 0.14139, 'rotation_loss_2': 0.35099, 'flip_loss': 0.71839, 'output_shaping_loss': 0.04785}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0656\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.07635, 'rotation_loss': 0.10581, 'rotation_loss_2': 0.24936, 'flip_loss': 0.86258, 'output_shaping_loss': 0.06272}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0763\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.07098, 'rotation_loss': 0.20615, 'rotation_loss_2': 0.4349, 'flip_loss': 1.39213, 'output_shaping_loss': 0.21802}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.071\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.71, 'score_outdist': 0.59}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.06115, 'rotation_loss': 0.15834, 'rotation_loss_2': 0.38576, 'flip_loss': 1.16337, 'output_shaping_loss': 0.16772}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0611\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.08418, 'rotation_loss': 0.1464, 'rotation_loss_2': 0.35599, 'flip_loss': 1.16904, 'output_shaping_loss': 0.17156}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0842\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.05776, 'rotation_loss': 0.09347, 'rotation_loss_2': 0.21643, 'flip_loss': 0.4422, 'output_shaping_loss': 0.0202}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0578\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.06398, 'rotation_loss': 0.11957, 'rotation_loss_2': 0.28433, 'flip_loss': 0.81331, 'output_shaping_loss': 0.07506}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.064\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.75 seconds\n",
      "{'supervised_loss': 0.07024, 'rotation_loss': 0.17714, 'rotation_loss_2': 0.45503, 'flip_loss': 2.3815, 'output_shaping_loss': 0.4996}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0702\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.96 seconds\n",
      "{'supervised_loss': 0.10095, 'rotation_loss': 0.2081, 'rotation_loss_2': 0.5156, 'flip_loss': 2.30385, 'output_shaping_loss': 0.4071}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.101\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.5 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.95 seconds\n",
      "{'supervised_loss': 0.09478, 'rotation_loss': 0.11965, 'rotation_loss_2': 0.32326, 'flip_loss': 1.43387, 'output_shaping_loss': 0.1796}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0948\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.0919, 'rotation_loss': 0.12048, 'rotation_loss_2': 0.30503, 'flip_loss': 1.01481, 'output_shaping_loss': 0.08519}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0919\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.85, 'score_outdist': 0.63}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.07534, 'rotation_loss': 0.16877, 'rotation_loss_2': 0.43241, 'flip_loss': 0.85151, 'output_shaping_loss': 0.07557}\n",
      "Done with chunk. Training took 32 seconds. Chunk loss was 0.0753\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.05922, 'rotation_loss': 0.19901, 'rotation_loss_2': 0.53709, 'flip_loss': 1.03782, 'output_shaping_loss': 0.16915}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0592\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.05114, 'rotation_loss': 0.21177, 'rotation_loss_2': 0.56238, 'flip_loss': 1.34384, 'output_shaping_loss': 0.24392}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0511\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.13365, 'rotation_loss': 0.24566, 'rotation_loss_2': 0.60251, 'flip_loss': 2.42222, 'output_shaping_loss': 0.42836}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1336\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.07948, 'rotation_loss': 0.09248, 'rotation_loss_2': 0.19104, 'flip_loss': 0.66623, 'output_shaping_loss': 0.06671}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0795\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.06178, 'rotation_loss': 0.11516, 'rotation_loss_2': 0.24505, 'flip_loss': 0.92891, 'output_shaping_loss': 0.11105}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0618\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.07485, 'rotation_loss': 0.13845, 'rotation_loss_2': 0.30892, 'flip_loss': 1.24517, 'output_shaping_loss': 0.18404}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0749\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.78 seconds\n",
      "{'supervised_loss': 0.0968, 'rotation_loss': 0.09283, 'rotation_loss_2': 0.25395, 'flip_loss': 0.91222, 'output_shaping_loss': 0.106}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0968\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.91, 'score_outdist': 0.62}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.83 seconds\n",
      "{'supervised_loss': 0.07156, 'rotation_loss': 0.09212, 'rotation_loss_2': 0.23438, 'flip_loss': 0.80746, 'output_shaping_loss': 0.0878}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0716\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.88 seconds\n",
      "{'supervised_loss': 0.09929, 'rotation_loss': 0.09216, 'rotation_loss_2': 0.20215, 'flip_loss': 0.51814, 'output_shaping_loss': 0.04984}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0993\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.51 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.71 seconds\n",
      "{'supervised_loss': 0.06163, 'rotation_loss': 0.09753, 'rotation_loss_2': 0.20086, 'flip_loss': 0.51909, 'output_shaping_loss': 0.04934}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0616\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.06922, 'rotation_loss': 0.0812, 'rotation_loss_2': 0.19095, 'flip_loss': 0.54798, 'output_shaping_loss': 0.06186}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0692\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.06142, 'rotation_loss': 0.09251, 'rotation_loss_2': 0.22953, 'flip_loss': 0.58913, 'output_shaping_loss': 0.03709}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0614\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.74 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.74 seconds\n",
      "{'supervised_loss': 0.05663, 'rotation_loss': 0.12302, 'rotation_loss_2': 0.30354, 'flip_loss': 0.97501, 'output_shaping_loss': 0.13436}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0566\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "{'supervised_loss': 0.05562, 'rotation_loss': 0.10417, 'rotation_loss_2': 0.24077, 'flip_loss': 0.84992, 'output_shaping_loss': 0.12523}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0556\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.25182, 'rotation_loss': 0.11116, 'rotation_loss_2': 0.23252, 'flip_loss': 2.30272, 'output_shaping_loss': 0.40841}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.2518\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.38, 'score_outdist': 0.2}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.16796, 'rotation_loss': 0.09779, 'rotation_loss_2': 0.18646, 'flip_loss': 0.74318, 'output_shaping_loss': 0.11454}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.168\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.10853, 'rotation_loss': 0.09484, 'rotation_loss_2': 0.21881, 'flip_loss': 0.54904, 'output_shaping_loss': 0.01913}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1085\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.69 seconds\n",
      "{'supervised_loss': 0.06414, 'rotation_loss': 0.11576, 'rotation_loss_2': 0.23221, 'flip_loss': 0.73579, 'output_shaping_loss': 0.07853}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0641\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.87 seconds\n",
      "{'supervised_loss': 0.06311, 'rotation_loss': 0.11029, 'rotation_loss_2': 0.21735, 'flip_loss': 0.72085, 'output_shaping_loss': 0.07249}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0631\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.83 seconds\n",
      "{'supervised_loss': 0.16254, 'rotation_loss': 0.09242, 'rotation_loss_2': 0.18289, 'flip_loss': 1.10706, 'output_shaping_loss': 0.17057}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1625\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.86 seconds\n",
      "{'supervised_loss': 0.10723, 'rotation_loss': 0.07952, 'rotation_loss_2': 0.18614, 'flip_loss': 0.73897, 'output_shaping_loss': 0.08788}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.1072\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.72 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.83 seconds\n",
      "{'supervised_loss': 0.07202, 'rotation_loss': 0.12112, 'rotation_loss_2': 0.24256, 'flip_loss': 0.88366, 'output_shaping_loss': 0.11338}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.072\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.67 seconds\n",
      "{'supervised_loss': 0.0359, 'rotation_loss': 0.11696, 'rotation_loss_2': 0.23645, 'flip_loss': 0.81601, 'output_shaping_loss': 0.0773}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0359\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.86, 'score_outdist': 0.63}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "{'supervised_loss': 0.07907, 'rotation_loss': 0.10786, 'rotation_loss_2': 0.2629, 'flip_loss': 0.82743, 'output_shaping_loss': 0.09001}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0791\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.2368, 'rotation_loss': 0.11034, 'rotation_loss_2': 0.30118, 'flip_loss': 1.31823, 'output_shaping_loss': 0.22562}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.2368\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.82 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.83 seconds\n",
      "{'supervised_loss': 0.13184, 'rotation_loss': 0.11581, 'rotation_loss_2': 0.27803, 'flip_loss': 1.0979, 'output_shaping_loss': 0.1193}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1318\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.08687, 'rotation_loss': 0.12107, 'rotation_loss_2': 0.26392, 'flip_loss': 1.04324, 'output_shaping_loss': 0.1262}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0869\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.01 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 1.17 seconds\n",
      "{'supervised_loss': 0.0661, 'rotation_loss': 0.14641, 'rotation_loss_2': 0.33274, 'flip_loss': 0.94394, 'output_shaping_loss': 0.09329}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0661\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.68 seconds\n",
      "{'supervised_loss': 0.14984, 'rotation_loss': 0.12453, 'rotation_loss_2': 0.27109, 'flip_loss': 1.34422, 'output_shaping_loss': 0.18882}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.1498\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.79 seconds\n",
      "{'supervised_loss': 0.09148, 'rotation_loss': 0.07536, 'rotation_loss_2': 0.19459, 'flip_loss': 0.7362, 'output_shaping_loss': 0.05551}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0915\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.76 seconds\n",
      "{'supervised_loss': 0.09249, 'rotation_loss': 0.09746, 'rotation_loss_2': 0.2329, 'flip_loss': 0.75564, 'output_shaping_loss': 0.0575}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0925\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.87, 'score_outdist': 0.51}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.96 seconds\n",
      "{'supervised_loss': 0.07935, 'rotation_loss': 0.11528, 'rotation_loss_2': 0.27767, 'flip_loss': 0.60529, 'output_shaping_loss': 0.0373}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0794\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.79 seconds\n",
      "{'supervised_loss': 0.07157, 'rotation_loss': 0.07929, 'rotation_loss_2': 0.20335, 'flip_loss': 0.44071, 'output_shaping_loss': 0.01836}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0716\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "{'supervised_loss': 0.06278, 'rotation_loss': 0.11018, 'rotation_loss_2': 0.25067, 'flip_loss': 0.74392, 'output_shaping_loss': 0.06539}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0628\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "{'supervised_loss': 0.06674, 'rotation_loss': 0.10788, 'rotation_loss_2': 0.2889, 'flip_loss': 0.61497, 'output_shaping_loss': 0.05188}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0667\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.07, 'rotation_loss': 0.14886, 'rotation_loss_2': 0.3729, 'flip_loss': 0.87663, 'output_shaping_loss': 0.09499}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.07\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.05117, 'rotation_loss': 0.10413, 'rotation_loss_2': 0.24972, 'flip_loss': 0.70463, 'output_shaping_loss': 0.07483}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0512\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "{'supervised_loss': 0.0624, 'rotation_loss': 0.10107, 'rotation_loss_2': 0.24421, 'flip_loss': 0.71932, 'output_shaping_loss': 0.06351}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0624\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.05793, 'rotation_loss': 0.10597, 'rotation_loss_2': 0.23062, 'flip_loss': 0.66726, 'output_shaping_loss': 0.05582}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0579\n",
      "\n",
      "validation took 12 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.96, 'score_outdist': 0.75}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.04849, 'rotation_loss': 0.13638, 'rotation_loss_2': 0.2616, 'flip_loss': 0.73504, 'output_shaping_loss': 0.07697}\n",
      "Done with chunk. Training took 32 seconds. Chunk loss was 0.0485\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "{'supervised_loss': 0.05152, 'rotation_loss': 0.10765, 'rotation_loss_2': 0.21173, 'flip_loss': 0.74446, 'output_shaping_loss': 0.07406}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0515\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.79 seconds\n",
      "{'supervised_loss': 0.08319, 'rotation_loss': 0.09916, 'rotation_loss_2': 0.20824, 'flip_loss': 0.59325, 'output_shaping_loss': 0.05273}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0832\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.83 seconds\n",
      "{'supervised_loss': 0.04923, 'rotation_loss': 0.09913, 'rotation_loss_2': 0.22249, 'flip_loss': 0.61674, 'output_shaping_loss': 0.04934}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0492\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.86 seconds\n",
      "{'supervised_loss': 0.08234, 'rotation_loss': 0.08728, 'rotation_loss_2': 0.20276, 'flip_loss': 0.58656, 'output_shaping_loss': 0.04104}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0823\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "{'supervised_loss': 0.07355, 'rotation_loss': 0.11232, 'rotation_loss_2': 0.2293, 'flip_loss': 0.61238, 'output_shaping_loss': 0.03993}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0735\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.85 seconds\n",
      "{'supervised_loss': 0.04948, 'rotation_loss': 0.12693, 'rotation_loss_2': 0.2687, 'flip_loss': 0.61066, 'output_shaping_loss': 0.05991}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0495\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.29647, 'rotation_loss': 0.1351, 'rotation_loss_2': 0.31659, 'flip_loss': 0.81533, 'output_shaping_loss': 0.10854}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.2965\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.56, 'score_outdist': 0.38}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.67 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.67 seconds\n",
      "{'supervised_loss': 0.12133, 'rotation_loss': 0.11202, 'rotation_loss_2': 0.23936, 'flip_loss': 0.44774, 'output_shaping_loss': 0.06673}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.1213\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.07889, 'rotation_loss': 0.24657, 'rotation_loss_2': 0.57323, 'flip_loss': 1.11658, 'output_shaping_loss': 0.18481}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0789\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.71 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.71 seconds\n",
      "{'supervised_loss': 0.06083, 'rotation_loss': 0.27738, 'rotation_loss_2': 0.6635, 'flip_loss': 1.61696, 'output_shaping_loss': 0.31127}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0608\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.05742, 'rotation_loss': 0.21799, 'rotation_loss_2': 0.5498, 'flip_loss': 1.22614, 'output_shaping_loss': 0.21016}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0574\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.05424, 'rotation_loss': 0.26534, 'rotation_loss_2': 0.57577, 'flip_loss': 1.27019, 'output_shaping_loss': 0.23672}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0542\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.68 seconds\n",
      "{'supervised_loss': 0.06286, 'rotation_loss': 0.31731, 'rotation_loss_2': 0.73479, 'flip_loss': 1.84947, 'output_shaping_loss': 0.39686}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0629\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.82 seconds\n",
      "{'supervised_loss': 0.07929, 'rotation_loss': 0.23547, 'rotation_loss_2': 0.56943, 'flip_loss': 1.07988, 'output_shaping_loss': 0.19488}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0793\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.91 seconds\n",
      "{'supervised_loss': 0.09325, 'rotation_loss': 0.18605, 'rotation_loss_2': 0.42176, 'flip_loss': 0.97127, 'output_shaping_loss': 0.1459}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0933\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.87, 'score_outdist': 0.53}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.53 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.78 seconds\n",
      "{'supervised_loss': 0.09514, 'rotation_loss': 0.20572, 'rotation_loss_2': 0.47078, 'flip_loss': 1.055, 'output_shaping_loss': 0.17072}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0951\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.71 seconds\n",
      "{'supervised_loss': 0.0688, 'rotation_loss': 0.28231, 'rotation_loss_2': 0.58694, 'flip_loss': 1.16871, 'output_shaping_loss': 0.20896}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0688\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "{'supervised_loss': 0.06961, 'rotation_loss': 0.23987, 'rotation_loss_2': 0.56475, 'flip_loss': 1.26127, 'output_shaping_loss': 0.22761}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0696\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.0625, 'rotation_loss': 0.16587, 'rotation_loss_2': 0.42597, 'flip_loss': 0.96158, 'output_shaping_loss': 0.13217}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0625\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.0918, 'rotation_loss': 0.07981, 'rotation_loss_2': 0.20468, 'flip_loss': 0.48987, 'output_shaping_loss': 0.02402}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0918\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.08341, 'rotation_loss': 0.08052, 'rotation_loss_2': 0.19443, 'flip_loss': 0.33764, 'output_shaping_loss': 0.03289}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0834\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.05518, 'rotation_loss': 0.1082, 'rotation_loss_2': 0.24346, 'flip_loss': 0.43736, 'output_shaping_loss': 0.03756}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0552\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.07076, 'rotation_loss': 0.10247, 'rotation_loss_2': 0.22757, 'flip_loss': 0.32775, 'output_shaping_loss': 0.0409}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0708\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.9, 'score_outdist': 0.39}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.06985, 'rotation_loss': 0.10561, 'rotation_loss_2': 0.25651, 'flip_loss': 0.34706, 'output_shaping_loss': 0.04098}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0699\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.74 seconds\n",
      "{'supervised_loss': 0.17354, 'rotation_loss': 0.08829, 'rotation_loss_2': 0.23055, 'flip_loss': 0.41797, 'output_shaping_loss': 0.0408}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1735\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.85 seconds\n",
      "{'supervised_loss': 0.11728, 'rotation_loss': 0.12593, 'rotation_loss_2': 0.31496, 'flip_loss': 0.46812, 'output_shaping_loss': 0.05541}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1173\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.53 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.8 seconds\n",
      "{'supervised_loss': 0.07553, 'rotation_loss': 0.13164, 'rotation_loss_2': 0.30385, 'flip_loss': 0.40549, 'output_shaping_loss': 0.03478}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0755\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.68 seconds\n",
      "{'supervised_loss': 0.08615, 'rotation_loss': 0.11734, 'rotation_loss_2': 0.281, 'flip_loss': 0.65617, 'output_shaping_loss': 0.06672}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0861\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.77 seconds\n",
      "{'supervised_loss': 0.06208, 'rotation_loss': 0.11251, 'rotation_loss_2': 0.25695, 'flip_loss': 0.8654, 'output_shaping_loss': 0.13354}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0621\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.0533, 'rotation_loss': 0.09057, 'rotation_loss_2': 0.19499, 'flip_loss': 0.93885, 'output_shaping_loss': 0.12408}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0533\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "{'supervised_loss': 0.04442, 'rotation_loss': 0.11309, 'rotation_loss_2': 0.25045, 'flip_loss': 0.9891, 'output_shaping_loss': 0.13296}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0444\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.96, 'score_outdist': 0.28}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.04473, 'rotation_loss': 0.13841, 'rotation_loss_2': 0.29949, 'flip_loss': 0.80589, 'output_shaping_loss': 0.10572}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0447\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.06197, 'rotation_loss': 0.12437, 'rotation_loss_2': 0.29827, 'flip_loss': 0.79658, 'output_shaping_loss': 0.08553}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.062\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.04733, 'rotation_loss': 0.10107, 'rotation_loss_2': 0.23402, 'flip_loss': 0.965, 'output_shaping_loss': 0.13196}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0473\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.04654, 'rotation_loss': 0.11007, 'rotation_loss_2': 0.24754, 'flip_loss': 0.72683, 'output_shaping_loss': 0.07675}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0465\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.71 seconds\n",
      "{'supervised_loss': 0.07059, 'rotation_loss': 0.13297, 'rotation_loss_2': 0.33562, 'flip_loss': 0.72943, 'output_shaping_loss': 0.10798}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0706\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.7 seconds\n",
      "{'supervised_loss': 0.12591, 'rotation_loss': 0.1184, 'rotation_loss_2': 0.25781, 'flip_loss': 1.00283, 'output_shaping_loss': 0.17893}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1259\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.9 seconds\n",
      "{'supervised_loss': 0.11191, 'rotation_loss': 0.139, 'rotation_loss_2': 0.33722, 'flip_loss': 1.03688, 'output_shaping_loss': 0.15989}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1119\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.78 seconds\n",
      "{'supervised_loss': 0.08068, 'rotation_loss': 0.21648, 'rotation_loss_2': 0.50309, 'flip_loss': 1.90574, 'output_shaping_loss': 0.33286}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0807\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.89, 'score_outdist': 0.25}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.67 seconds\n",
      "{'supervised_loss': 0.05894, 'rotation_loss': 0.17042, 'rotation_loss_2': 0.37858, 'flip_loss': 1.62229, 'output_shaping_loss': 0.2648}\n",
      "Done with chunk. Training took 34 seconds. Chunk loss was 0.0589\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "{'supervised_loss': 0.05976, 'rotation_loss': 0.16167, 'rotation_loss_2': 0.38295, 'flip_loss': 1.63694, 'output_shaping_loss': 0.26235}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0598\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.06115, 'rotation_loss': 0.1959, 'rotation_loss_2': 0.39311, 'flip_loss': 1.44366, 'output_shaping_loss': 0.21792}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0612\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.06341, 'rotation_loss': 0.26547, 'rotation_loss_2': 0.60271, 'flip_loss': 2.44143, 'output_shaping_loss': 0.45425}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0634\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "{'supervised_loss': 0.06623, 'rotation_loss': 0.18857, 'rotation_loss_2': 0.41345, 'flip_loss': 1.99352, 'output_shaping_loss': 0.36914}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0662\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "{'supervised_loss': 0.07413, 'rotation_loss': 0.21786, 'rotation_loss_2': 0.60196, 'flip_loss': 1.37576, 'output_shaping_loss': 0.21262}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0741\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.05854, 'rotation_loss': 0.39714, 'rotation_loss_2': 1.07973, 'flip_loss': 1.86872, 'output_shaping_loss': 0.36124}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0585\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.05679, 'rotation_loss': 0.40141, 'rotation_loss_2': 0.93835, 'flip_loss': 2.24865, 'output_shaping_loss': 0.46747}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0568\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 14 seconds\n",
      "{'score_indist': 0.9, 'score_outdist': 0.44}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.79 seconds\n",
      "{'supervised_loss': 0.05521, 'rotation_loss': 0.64216, 'rotation_loss_2': 1.42469, 'flip_loss': 3.9641, 'output_shaping_loss': 0.94211}\n",
      "Done with chunk. Training took 34 seconds. Chunk loss was 0.0552\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.8 seconds\n",
      "{'supervised_loss': 0.07414, 'rotation_loss': 0.28557, 'rotation_loss_2': 0.66532, 'flip_loss': 1.94468, 'output_shaping_loss': 0.42154}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0741\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.89 seconds\n",
      "{'supervised_loss': 0.09517, 'rotation_loss': 0.41804, 'rotation_loss_2': 0.8576, 'flip_loss': 1.68506, 'output_shaping_loss': 0.34552}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0952\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.75 seconds\n",
      "{'supervised_loss': 0.06005, 'rotation_loss': 0.12795, 'rotation_loss_2': 0.31324, 'flip_loss': 0.45593, 'output_shaping_loss': 0.04905}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0601\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.67 seconds\n",
      "{'supervised_loss': 0.0459, 'rotation_loss': 0.1462, 'rotation_loss_2': 0.3635, 'flip_loss': 0.47184, 'output_shaping_loss': 0.03187}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0459\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "{'supervised_loss': 0.07892, 'rotation_loss': 0.17479, 'rotation_loss_2': 0.40717, 'flip_loss': 0.47197, 'output_shaping_loss': 0.03755}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0789\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.05165, 'rotation_loss': 0.1269, 'rotation_loss_2': 0.30472, 'flip_loss': 0.57843, 'output_shaping_loss': 0.06406}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0516\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.05795, 'rotation_loss': 0.14592, 'rotation_loss_2': 0.34891, 'flip_loss': 0.60276, 'output_shaping_loss': 0.08355}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.058\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.82, 'score_outdist': 0.29}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.05235, 'rotation_loss': 0.11685, 'rotation_loss_2': 0.29447, 'flip_loss': 0.5033, 'output_shaping_loss': 0.06628}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0524\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.67 seconds\n",
      "{'supervised_loss': 0.04964, 'rotation_loss': 0.07804, 'rotation_loss_2': 0.19258, 'flip_loss': 0.3516, 'output_shaping_loss': 0.03216}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0496\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.74 seconds\n",
      "{'supervised_loss': 0.05489, 'rotation_loss': 0.09228, 'rotation_loss_2': 0.20561, 'flip_loss': 0.47785, 'output_shaping_loss': 0.0554}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0549\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.71 seconds\n",
      "{'supervised_loss': 0.05588, 'rotation_loss': 0.09743, 'rotation_loss_2': 0.23886, 'flip_loss': 0.79222, 'output_shaping_loss': 0.12088}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0559\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.69 seconds\n",
      "{'supervised_loss': 0.03743, 'rotation_loss': 0.14648, 'rotation_loss_2': 0.368, 'flip_loss': 1.06586, 'output_shaping_loss': 0.17973}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0374\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.89 seconds\n",
      "{'supervised_loss': 0.04706, 'rotation_loss': 0.13639, 'rotation_loss_2': 0.34975, 'flip_loss': 1.01329, 'output_shaping_loss': 0.15025}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0471\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.81 seconds\n",
      "{'supervised_loss': 0.0652, 'rotation_loss': 0.10202, 'rotation_loss_2': 0.24659, 'flip_loss': 0.72851, 'output_shaping_loss': 0.08959}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0652\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.76 seconds\n",
      "{'supervised_loss': 0.0661, 'rotation_loss': 0.1529, 'rotation_loss_2': 0.37246, 'flip_loss': 0.75836, 'output_shaping_loss': 0.12058}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0661\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 14 seconds\n",
      "{'score_indist': 0.94, 'score_outdist': 0.64}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.04045, 'rotation_loss': 0.38383, 'rotation_loss_2': 0.95359, 'flip_loss': 1.78736, 'output_shaping_loss': 0.46369}\n",
      "Done with chunk. Training took 34 seconds. Chunk loss was 0.0405\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.05023, 'rotation_loss': 0.38487, 'rotation_loss_2': 0.94936, 'flip_loss': 2.41189, 'output_shaping_loss': 0.66334}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0502\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.63 seconds\n",
      "{'supervised_loss': 0.04032, 'rotation_loss': 1.02862, 'rotation_loss_2': 2.44469, 'flip_loss': 6.78346, 'output_shaping_loss': 1.83057}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0403\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "{'supervised_loss': 0.12067, 'rotation_loss': 0.5631, 'rotation_loss_2': 1.26117, 'flip_loss': 4.8815, 'output_shaping_loss': 1.15071}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1207\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.11463, 'rotation_loss': 0.36626, 'rotation_loss_2': 0.987, 'flip_loss': 2.29247, 'output_shaping_loss': 0.38246}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1146\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.68 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.73 seconds\n",
      "{'supervised_loss': 0.06136, 'rotation_loss': 0.42928, 'rotation_loss_2': 1.07839, 'flip_loss': 3.91766, 'output_shaping_loss': 0.81748}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0614\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.54 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.72 seconds\n",
      "{'supervised_loss': 0.0616, 'rotation_loss': 0.56076, 'rotation_loss_2': 1.4424, 'flip_loss': 3.79795, 'output_shaping_loss': 0.82053}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0616\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.69 seconds\n",
      "{'supervised_loss': 0.05925, 'rotation_loss': 0.32629, 'rotation_loss_2': 0.89382, 'flip_loss': 1.36816, 'output_shaping_loss': 0.20501}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0593\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 13 seconds\n",
      "{'score_indist': 0.87, 'score_outdist': 0.31}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.74 seconds\n",
      "{'supervised_loss': 0.07975, 'rotation_loss': 0.2951, 'rotation_loss_2': 0.78891, 'flip_loss': 1.4502, 'output_shaping_loss': 0.24311}\n",
      "Done with chunk. Training took 33 seconds. Chunk loss was 0.0797\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.55 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.79 seconds\n",
      "{'supervised_loss': 0.08314, 'rotation_loss': 0.23267, 'rotation_loss_2': 0.61749, 'flip_loss': 0.84635, 'output_shaping_loss': 0.09878}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.0831\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.56 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.8 seconds\n",
      "{'supervised_loss': 0.08591, 'rotation_loss': 0.17192, 'rotation_loss_2': 0.46007, 'flip_loss': 0.91817, 'output_shaping_loss': 0.11856}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0859\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.53 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.64 seconds\n",
      "{'supervised_loss': 0.07249, 'rotation_loss': 0.23187, 'rotation_loss_2': 0.57796, 'flip_loss': 0.85389, 'output_shaping_loss': 0.09371}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0725\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.04478, 'rotation_loss': 0.24959, 'rotation_loss_2': 0.67414, 'flip_loss': 0.83749, 'output_shaping_loss': 0.09699}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0448\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "{'supervised_loss': 0.18774, 'rotation_loss': 0.34925, 'rotation_loss_2': 0.84967, 'flip_loss': 1.42299, 'output_shaping_loss': 0.23899}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.1877\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.61 seconds\n",
      "{'supervised_loss': 0.12913, 'rotation_loss': 0.23135, 'rotation_loss_2': 0.59046, 'flip_loss': 0.55583, 'output_shaping_loss': 0.05205}\n",
      "Done with chunk. Training took 8 seconds. Chunk loss was 0.1291\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.59 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "{'supervised_loss': 0.0732, 'rotation_loss': 0.12134, 'rotation_loss_2': 0.2863, 'flip_loss': 0.47375, 'output_shaping_loss': 0.03384}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0732\n",
      "\n",
      "validation took 13 seconds\n",
      "validation took 14 seconds\n",
      "{'score_indist': 0.88, 'score_outdist': 0.52}\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.62 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.05267, 'rotation_loss': 0.068, 'rotation_loss_2': 0.17631, 'flip_loss': 0.34552, 'output_shaping_loss': 0.07215}\n",
      "Done with chunk. Training took 34 seconds. Chunk loss was 0.0527\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.6 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.66 seconds\n",
      "{'supervised_loss': 0.04224, 'rotation_loss': 0.06765, 'rotation_loss_2': 0.17978, 'flip_loss': 0.39941, 'output_shaping_loss': 0.03807}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0422\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.57 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.65 seconds\n",
      "{'supervised_loss': 0.07813, 'rotation_loss': 0.08794, 'rotation_loss_2': 0.20995, 'flip_loss': 0.3479, 'output_shaping_loss': 0.0626}\n",
      "Done with chunk. Training took 7 seconds. Chunk loss was 0.0781\n",
      "\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.58 seconds\n",
      "Queueing chunk of size torch.Size([200, 64, 3, 64, 64]) took 0.81 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4c0aa5b2ebb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-7ff156d62f6d>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mpred_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfront_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_src_domain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mpred_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_flip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_rot_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_rot_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_rot_pos_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_rot_neg_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfront_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/procgen/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/carlita/train_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, aux, hidden, return_salmap, register_activations, is_src_domain)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregister_activations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0msalmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
