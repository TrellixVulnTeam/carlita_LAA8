{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import threading\n",
    "\n",
    "from train_utils import *\n",
    "\n",
    "import gym3\n",
    "from procgen import ProcgenGym3Env\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'; device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "\n",
    "color_lookup = {\n",
    "    'all':[0,1,2,3,4,5,6,7],\n",
    "    'outer':[0,1,6,7],\n",
    "    'inner':[2,3,4,5]\n",
    "}\n",
    "backgrounds = ['all', 'outer', 'inner']\n",
    "roads = ['all', 'outer', 'inner']\n",
    "backnoises = [0, 100]\n",
    "\n",
    "configs = []\n",
    "for bg in backgrounds:\n",
    "    for rd in roads:\n",
    "        for backnoise in backnoises:\n",
    "            config = { \n",
    "                'name':f\"bg:{bg} rd:{rd} noise:{backnoise}\",\n",
    "                'color_theme': color_lookup[bg],\n",
    "                'color_theme_road':color_lookup[rd],\n",
    "                'background_noise_level':backnoise\n",
    "            }\n",
    "            configs.append(config)\n",
    "\n",
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(config, bs=bs):\n",
    "    return ProcgenGym3Env(num=bs, env_name=\"testgame\", num_levels=100_000, start_level=0,\n",
    "                         color_theme=config['color_theme'],\n",
    "                         color_theme_road=config['color_theme_road'],\n",
    "                         background_noise_level=config['background_noise_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config = configs[0]\\n\\ns = np.array([[.0,.0] for _ in range(bs)], dtype=np.float32)\\nseq_len = 15\\nN_IMGS = 4\\n\\nplt.figure(figsize=(20, 10))\\n\\ntitles=[\\'indist\\', \\'outdist\\']\\n\\nfor i, title in enumerate(titles):\\n    ax = plt.subplot(1,5, i+1)\\n    env = get_env(title, config)\\n\\n    for i in range(seq_len):\\n        env.act(s)\\n        rew, obs, first = env.observe()\\n        img = obs[\\'rgb\\']\\n        img = np.concatenate(img[:N_IMGS],0)\\n        info = env.get_info()\\n        \\n    plt.imshow(img)\\n    plt.title(f\"{config[\\'name\\']}: {title}\")\\n    plt.axis(\"off\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"config = configs[0]\n",
    "\n",
    "s = np.array([[.0,.0] for _ in range(bs)], dtype=np.float32)\n",
    "seq_len = 15\n",
    "N_IMGS = 4\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "titles=['indist', 'outdist']\n",
    "\n",
    "for i, title in enumerate(titles):\n",
    "    ax = plt.subplot(1,5, i+1)\n",
    "    env = get_env(title, config)\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        env.act(s)\n",
    "        rew, obs, first = env.observe()\n",
    "        img = obs['rgb']\n",
    "        img = np.concatenate(img[:N_IMGS],0)\n",
    "        info = env.get_info()\n",
    "        \n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{config['name']}: {title}\")\n",
    "    plt.axis(\"off\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdrive(m, use_autopilot, config):\n",
    "    TRAINING_WHEELS_WINDOW = 10\n",
    "    m.eval()\n",
    "    seq_len = 400\n",
    "    bs = 256\n",
    "    val_env = get_env(config, bs=bs)\n",
    "    s = np.array([[.0,.0] for _ in range(bs)], dtype=np.float32)\n",
    "    reward = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(seq_len):\n",
    "            val_env.act(s)\n",
    "            rew, obs, first = val_env.observe()\n",
    "            reward += rew.sum()\n",
    "            img = obs['rgb']\n",
    "            info = val_env.get_info()\n",
    "            autopilot_control = np.array([[e[\"autopilot_\"+c] for c in control_properties] for e in info])\n",
    "            aux = np.array([[e[a] for a in aux_properties] for e in info])\n",
    "            front = torch.from_numpy(img.astype(np.float32)/255.).unsqueeze(0).permute(0,1,4,2,3).to(device)\n",
    "            aux = torch.from_numpy(aux.astype(np.float32)).unsqueeze(0).to(device)\n",
    "            \n",
    "            if use_autopilot or i < TRAINING_WHEELS_WINDOW:\n",
    "                s = autopilot_control\n",
    "            else:\n",
    "                out, _ = m(front, aux, '')\n",
    "                s = out.squeeze(0).squeeze(-1).cpu().numpy()\n",
    "                s = np.clip(s, -5., 5.)\n",
    "        \n",
    "    reward /= (bs*seq_len)\n",
    "    val_env.close()\n",
    "    m.train()\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss().cuda()\n",
    "def get_model():\n",
    "    m = VizCNN(use_rnn=False).to(device);\n",
    "    opt = torch.optim.Adam(m.parameters(), lr=3e-4)\n",
    "    scaler = torch.cuda.amp.GradScaler() \n",
    "    return m, opt, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(config):\n",
    "    m, opt, scaler = get_model()\n",
    "    global bs\n",
    "    dataloader = DataLoader(env=get_env(config, bs=bs), bs=bs, seq_len=200)\n",
    "\n",
    "    m.train()\n",
    "    logger = Logger()\n",
    "    n_updates = 100\n",
    "    counter = 1\n",
    "    log_cadence = 5_000\n",
    "    bptt = 1\n",
    "\n",
    "    while counter < n_updates:\n",
    "        front_container, aux_container, target_container = dataloader.get_chunk()\n",
    "        chunk_len, bs, _, _, _ = front_container.shape\n",
    "        len_ix = 0\n",
    "        while len_ix < chunk_len:\n",
    "            front = front_container[len_ix:len_ix+bptt, :, :, :, :].to(device).half()\n",
    "            aux = aux_container[len_ix:len_ix+bptt, :, :].to(device).half()\n",
    "            target = target_container[len_ix:len_ix+bptt, :, :].to(device).half()\n",
    "            len_ix += bptt*4\n",
    "            with torch.cuda.amp.autocast(): pred, _ = m(front, aux, '')  \n",
    "            loss = loss_fn(target, pred)\n",
    "            scaler.scale(loss).backward() \n",
    "            scaler.step(opt) \n",
    "            scaler.update() \n",
    "            opt.zero_grad()\n",
    "            counter += 1\n",
    "\n",
    "    torch.save(m.state_dict(), config['name']+\".torch\")\n",
    "    \n",
    "    dataloader.destroy()\n",
    "    del dataloader, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training  {'name': 'bg:all rd:all noise:0', 'color_theme': [0, 1, 2, 3, 4, 5, 6, 7], 'color_theme_road': [0, 1, 2, 3, 4, 5, 6, 7], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:all rd:all noise:100', 'color_theme': [0, 1, 2, 3, 4, 5, 6, 7], 'color_theme_road': [0, 1, 2, 3, 4, 5, 6, 7], 'background_noise_level': 100}\n",
      "training  {'name': 'bg:all rd:outer noise:0', 'color_theme': [0, 1, 2, 3, 4, 5, 6, 7], 'color_theme_road': [0, 1, 6, 7], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:all rd:outer noise:100', 'color_theme': [0, 1, 2, 3, 4, 5, 6, 7], 'color_theme_road': [0, 1, 6, 7], 'background_noise_level': 100}\n",
      "training  {'name': 'bg:all rd:inner noise:0', 'color_theme': [0, 1, 2, 3, 4, 5, 6, 7], 'color_theme_road': [2, 3, 4, 5], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:all rd:inner noise:100', 'color_theme': [0, 1, 2, 3, 4, 5, 6, 7], 'color_theme_road': [2, 3, 4, 5], 'background_noise_level': 100}\n",
      "training  {'name': 'bg:outer rd:all noise:0', 'color_theme': [0, 1, 6, 7], 'color_theme_road': [0, 1, 2, 3, 4, 5, 6, 7], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:outer rd:all noise:100', 'color_theme': [0, 1, 6, 7], 'color_theme_road': [0, 1, 2, 3, 4, 5, 6, 7], 'background_noise_level': 100}\n",
      "training  {'name': 'bg:outer rd:outer noise:0', 'color_theme': [0, 1, 6, 7], 'color_theme_road': [0, 1, 6, 7], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:outer rd:outer noise:100', 'color_theme': [0, 1, 6, 7], 'color_theme_road': [0, 1, 6, 7], 'background_noise_level': 100}\n",
      "training  {'name': 'bg:outer rd:inner noise:0', 'color_theme': [0, 1, 6, 7], 'color_theme_road': [2, 3, 4, 5], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:outer rd:inner noise:100', 'color_theme': [0, 1, 6, 7], 'color_theme_road': [2, 3, 4, 5], 'background_noise_level': 100}\n",
      "training  {'name': 'bg:inner rd:all noise:0', 'color_theme': [2, 3, 4, 5], 'color_theme_road': [0, 1, 2, 3, 4, 5, 6, 7], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:inner rd:all noise:100', 'color_theme': [2, 3, 4, 5], 'color_theme_road': [0, 1, 2, 3, 4, 5, 6, 7], 'background_noise_level': 100}\n",
      "training  {'name': 'bg:inner rd:outer noise:0', 'color_theme': [2, 3, 4, 5], 'color_theme_road': [0, 1, 6, 7], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:inner rd:outer noise:100', 'color_theme': [2, 3, 4, 5], 'color_theme_road': [0, 1, 6, 7], 'background_noise_level': 100}\n",
      "training  {'name': 'bg:inner rd:inner noise:0', 'color_theme': [2, 3, 4, 5], 'color_theme_road': [2, 3, 4, 5], 'background_noise_level': 0}\n",
      "training  {'name': 'bg:inner rd:inner noise:100', 'color_theme': [2, 3, 4, 5], 'color_theme_road': [2, 3, 4, 5], 'background_noise_level': 100}\n"
     ]
    }
   ],
   "source": [
    "for config in configs:\n",
    "    print(\"training \", config)\n",
    "    train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for config_test in configs:\n",
    "    m, _, _ = get_model()\n",
    "    baseline_score = testdrive(m, use_autopilot=True, config=config_test)\n",
    "    \n",
    "    for config_train in configs:\n",
    "        m.load_state_dict(torch.load(config_train['name']+\".torch\"))\n",
    "        score = testdrive(m, use_autopilot=False, config=config_test) / baseline_score\n",
    "        result = {'trn_env':config_train['name'],\n",
    "                 'test_env':config_test['name'],\n",
    "                 'score':score}\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>test_env</th>\n",
       "      <th>bg:all rd:all noise:0</th>\n",
       "      <th>bg:all rd:all noise:100</th>\n",
       "      <th>bg:all rd:outer noise:0</th>\n",
       "      <th>bg:all rd:outer noise:100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trn_env</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bg:all rd:all noise:0</th>\n",
       "      <td>0.137656</td>\n",
       "      <td>0.128424</td>\n",
       "      <td>0.135654</td>\n",
       "      <td>0.138938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg:all rd:all noise:100</th>\n",
       "      <td>0.173934</td>\n",
       "      <td>0.154778</td>\n",
       "      <td>0.178464</td>\n",
       "      <td>0.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg:all rd:outer noise:0</th>\n",
       "      <td>0.136120</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>0.149836</td>\n",
       "      <td>0.141311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg:all rd:outer noise:100</th>\n",
       "      <td>0.165621</td>\n",
       "      <td>0.176746</td>\n",
       "      <td>0.206590</td>\n",
       "      <td>0.203475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "test_env                   bg:all rd:all noise:0  bg:all rd:all noise:100  \\\n",
       "trn_env                                                                     \n",
       "bg:all rd:all noise:0                   0.137656                 0.128424   \n",
       "bg:all rd:all noise:100                 0.173934                 0.154778   \n",
       "bg:all rd:outer noise:0                 0.136120                 0.138584   \n",
       "bg:all rd:outer noise:100               0.165621                 0.176746   \n",
       "\n",
       "test_env                   bg:all rd:outer noise:0  bg:all rd:outer noise:100  \n",
       "trn_env                                                                        \n",
       "bg:all rd:all noise:0                     0.135654                   0.138938  \n",
       "bg:all rd:all noise:100                   0.178464                   0.183400  \n",
       "bg:all rd:outer noise:0                   0.149836                   0.141311  \n",
       "bg:all rd:outer noise:100                 0.206590                   0.203475  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot(index='trn_env', columns='test_env', values='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
