{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import threading\n",
    "\n",
    "from train_utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym3\n",
    "from procgen import ProcgenGym3Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building procgen...done\n"
     ]
    }
   ],
   "source": [
    "bs = 1\n",
    "\n",
    "# num_levels=1, start_level=6\n",
    "env = ProcgenGym3Env(num=bs, env_name=\"testgame\", render_mode='rgb_array')\n",
    "env = gym3.ViewerWrapper(env, info_key=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VizCNN(\n",
       "  (pooler): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (act): ReLU()\n",
       "  (conv_1a): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2a): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2b): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_3a): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_4a): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc0): Linear(in_features=5189, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "m = VizCNN(use_rnn=False).to(device);\n",
    "m.load_state_dict(torch.load(\"m_cons_3.27.torch\"))\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = get_hidden(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "SETTING DAGGER\n",
      "CPU times: user 481 ms, sys: 53 ms, total: 534 ms\n",
      "Wall time: 389 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "use_autopilot = True\n",
    "\n",
    "s = np.array([[.1, .2] for _ in range(bs)], dtype=np.float32)\n",
    "daggerized_controls = s\n",
    "\n",
    "\n",
    "seq_len = 1000\n",
    "DAGGER_CADENCE = 100\n",
    "DAGGER_DURATION = 10\n",
    "do_dagger = False\n",
    "dagger_counter = 0\n",
    "TRAINING_WHEELS_WINDOW = 20\n",
    "use_training_wheels = False\n",
    "\n",
    "act_grads = []\n",
    "imgs = []\n",
    "salmaps = []\n",
    "\n",
    "#with torch.no_grad():\n",
    "for i in range(seq_len):\n",
    "    env.act(s)\n",
    "    rew, obs, first = env.observe()\n",
    "    img = obs['rgb']\n",
    "    info = env.get_info()\n",
    "\n",
    "    aux = np.array([[e[a] for a in aux_properties] for e in info])\n",
    "    autopilot_controls = np.array([[e['autopilot_steer'], e['autopilot_throttle']] for e in info])\n",
    "\n",
    "    front = torch.from_numpy(img.astype(np.float32)/255.).unsqueeze(0).permute(0,1,4,2,3)\n",
    "    aux = torch.from_numpy(aux.astype(np.float32)).unsqueeze(0)\n",
    "\n",
    "    if use_autopilot:\n",
    "        if i % DAGGER_CADENCE == 0:\n",
    "            print('SETTING DAGGER')\n",
    "            dagger_counter = 0\n",
    "            steer_aug = random.uniform(-.3, .3)\n",
    "            #throttle_aug = random.uniform(.5, 1.5)\n",
    "            daggerized_controls = np.array([[c[0]+steer_aug, c[1]] for c in autopilot_controls])\n",
    "            do_dagger = True\n",
    "\n",
    "        if do_dagger:\n",
    "            s = daggerized_controls\n",
    "            dagger_counter+=1\n",
    "        else:\n",
    "            s = autopilot_controls\n",
    "\n",
    "        if dagger_counter == DAGGER_DURATION:\n",
    "            do_dagger = False\n",
    "\n",
    "    else:\n",
    "        front = front.to(device)\n",
    "        aux = aux.to(device)\n",
    "        out,hidden, salmap = m(front, aux, hidden, return_salmap=True, register_activations=True)\n",
    "        out[:,:,1]=.6\n",
    "        s = out.squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        \n",
    "        \"\"\"        baseline = torch.zeros_like(front)\n",
    "        steps = 100\n",
    "        grads = []\n",
    "\n",
    "        for i in range(0,steps+1):\n",
    "            mixed_img = baseline + (float(i)/steps)*(front-baseline)\n",
    "            m.zero_grad()\n",
    "            out, hidden, salmap = m(mixed_img, aux, hidden, return_salmap=True, register_activations=True)\n",
    "            out[0][0][0].backward(retain_graph=m.use_rnn) # Steer\n",
    "            g = m.get_activations_gradient()\n",
    "            g = g[0].mean(0).cpu().numpy()\n",
    "            grads.append(g)\n",
    "\n",
    "        avg_grads = np.stack(grads).mean(0)\n",
    "        act_grad = avg_grads\n",
    "        \n",
    "        salmap = salmap[0].mean(0)\n",
    "        \n",
    "        act_grads.append(act_grad * salmap)\n",
    "        #act_grads.append(salmap) # This by itself is pretty nice\n",
    "        \n",
    "        imgs.append(img[0])\"\"\"\n",
    "\n",
    "    if use_training_wheels and i < TRAINING_WHEELS_WINDOW:\n",
    "        s = autopilot_controls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def img_cam(act_grad, img, std):\n",
    "    # Gradients zero to one\n",
    "    act_grad = cv2.resize(act_grad, (img.shape[0],img.shape[1]))\n",
    "    mask = np.where(act_grad, (abs(act_grad)>std*2), 0)\n",
    "    mask = np.expand_dims(mask, -1)\n",
    "    \n",
    "    act_grad -= act_grad.min()\n",
    "    act_grad = act_grad / act_grad.max()\n",
    "    \n",
    "    # Make a three-channel heatmap out of the one channel gradients\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * act_grad), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    heatmap = heatmap * mask\n",
    "    heatmap = heatmap * 255\n",
    "    \n",
    "    #img = img / 255\n",
    "    \n",
    "    cam = heatmap*.5 + img\n",
    "    \n",
    "    #cam = cam / cam.max()\n",
    "    #cam = cam * 255\n",
    "    cam = np.clip(cam, 0, 255)\n",
    "    cam = cam.astype(np.uint8)\n",
    "    \n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beans/anaconda3/envs/procgen/lib/python3.7/site-packages/numpy/core/_methods.py:234: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/beans/anaconda3/envs/procgen/lib/python3.7/site-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/beans/anaconda3/envs/procgen/lib/python3.7/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "std = np.array(act_grads[20:]).std()\n",
    "img_cams = []\n",
    "for img, act_grad in zip(imgs,act_grads):\n",
    "    img_cams.append(img_cam(act_grad,img,std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img1 = img_cams[0]\n",
    "height , width , layers = img1.shape\n",
    "fps = 10\n",
    "\n",
    "video = cv2.VideoWriter('cams.avi', cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (width,height))\n",
    "\n",
    "for i in range(len(img_cams)-1):\n",
    "    img = img_cams[i] # cv2 expects out of 255, integers\n",
    "    video.write(img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 29, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
